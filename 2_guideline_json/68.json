{
    "number": 68,
    "label": 2,
    "source": "NIST",
    "subject": "Guide to Data-Centric System Threat Modeling",
    "document(english)": "DRAFT Special Publication 800-154, Guide to Data-Centric System Threat Modeling  Draft NIST Special Publication 800-154 1  2  Guide to Data-Centric System  3  Threat Modeling 4  5  6  7  Murugiah Souppaya 8  Karen Scarfone 9  10  11  12  13  14  15  16  C  O  M  P  U  T  E  R  S  E  C  U  R  I  T  Y 17  18  19  Draft NIST Special Publication 800-154 20  21  22  Guide to Data-Centric System  23  Threat Modeling 24  25  26  Murugiah Souppaya 27  Computer Security Division 28  Information Technology Laboratory 29  30  Karen Scarfone 31  Scarfone Cybersecurity 32  Clifton, VA 33  34  35  36  37  38  39  40  March 2016 41  42  43  44  45  46  U.S. Department of Commerce 47  Penny Pritzker, Secretary 48  49  National Institute of Standards and Technology  50  Willie May, Under Secretary of Commerce for Standards and Technology and Director 51  i  Authority 52  This publication has been developed by NIST in accordance with its statutory responsibilities under the 53  Federal Information Security Modernization Act (FISMA) of 2014, 44 U.S.C. § 3541 et seq., Public Law  54  (P.L.) 113-283. NIST is responsible for developing information security standards and guidelines, 55  including minimum requirements for federal information systems, but such standards and guidelines shall 56  not apply to national security systems without the express approval of appropriate federal officials 57  exercising policy authority over such systems. This guideline is consistent with the requirements of the 58  Office of Management and Budget (OMB) Circular A-130. 59  Nothing in this publication should be taken to contradict the standards and guidelines made mandatory 60  and binding on federal agencies by the Secretary of Commerce under statutory authority. Nor should 61  these guidelines be interpreted as altering or superseding the existing authorities of the Secretary of 62  Commerce, Director of the OMB, or any other federal official.  This publication may be used by 63  nongovernmental organizations on a voluntary basis and is not subject to copyright in the United States. 64  Attribution would, however, be appreciated by NIST.  65  National Institute of Standards and Technology Special Publication 800-154 66  Natl. Inst. Stand. Technol. Spec. Publ. 800-154, 25 pages (March 2016) 67  CODEN: NSPUE2 68  Certain commercial entities, equipment, or materials may be identified in this document in order to describe an 69  experimental procedure or concept adequately. Such identification is not intended to imply recommendation or 70  endorsement by NIST, nor is it intended to imply that the entities, materials, or equipment are necessarily the best 71  available for the purpose.  72  There may be references in this publication to other publications currently under development by NIST in 73  accordance with its assigned statutory responsibilities. The information in this publication, including concepts and 74  methodologies, may be used by federal agencies even before the completion of such companion publications. Thus, 75  until each publication is completed, current requirements, guidelines, and procedures, where they exist, remain 76  operative. For planning and transition purposes, federal agencies may wish to closely follow the development of 77  these new publications by NIST.  78  Organizations are encouraged to review all draft publications during public comment periods and provide feedback 79  to NIST. Many NIST cybersecurity publications, other than the ones noted above, are available at 80  http://csrc.nist.gov/publications. 81  82  Public comment period: March 14, 2016 through April 15, 2016 83  All comments are subject to release under the Freedom of Information Act (FOIA). 84  National Institute of Standards and Technology 85  Attn: Computer Security Division, Information Technology Laboratory 86  100 Bureau Drive (Mail Stop 8930) Gaithersburg, MD 20899-8930 87  Email: 800-154comments@nist.gov 88  89  http://csrc.nist.gov/publications  ii  Reports on Computer Systems Technology 90  The Information Technology Laboratory (ITL) at the National Institute of Standards and Technology 91  (NIST) promotes the U.S. economy and public welfare by providing technical leadership for the Nation’s 92  measurement and standards infrastructure. ITL develops tests, test methods, reference data, proof of 93  concept implementations, and technical analyses to advance the development and productive use of 94  information technology. ITL’s responsibilities include the development of management, administrative, 95  technical, and physical standards and guidelines for the cost-effective security and privacy of other than 96  national security-related information in federal information systems. The Special Publication 800-series 97  reports on ITL’s research, guidelines, and outreach efforts in information system security, and its 98  collaborative activities with industry, government, and academic organizations. 99  100  Abstract 101  Threat modeling is a form of risk assessment that models aspects of the attack and defense sides of a 102  particular logical entity, such as a piece of data, an application, a host, a system, or an environment. This 103  publication examines data-centric system threat modeling, which is threat modeling that is focused on 104  protecting particular types of data within systems. The publication provides information on the basics of 105  data-centric system threat modeling so that organizations can successfully use it as part of their risk 106  management processes. The general methodology provided by the publication is not intended to replace 107  existing methodologies, but rather to define fundamental principles that should be part of any sound data-108  centric system threat modeling methodology. 109  110  Keywords 111  data security; information security; risk assessment; risk management; threat modeling; threats; 112  vulnerabilities  113  114  Trademark Information 115  All trademarks or registered trademarks belong to their respective organizations. 116  117  Acknowledgments 118  The authors, Murugiah Souppaya of the National Institute of Standards and Technology (NIST) and 119  Karen Scarfone of Scarfone Cybersecurity, wish to thank their colleagues who reviewed drafts of this 120  document and contributed to its technical content. 121  122  iii  Table of Contents 123  Executive Summary ................................................................................................................. 1 124  1. Introduction ...................................................................................................................... 2 125  1.1 Purpose and Scope ................................................................................................... 2 126  1.2 Audience ................................................................................................................... 2 127  1.3 Document Structure .................................................................................................. 2 128  2. Attack and Defense Basics .............................................................................................. 3 129  2.1 The Attack Side ......................................................................................................... 3 130  2.1.1 Vulnerability .................................................................................................. 3 131  2.1.2 Exploit and Attack ......................................................................................... 4 132  2.1.3 Attack Vector ................................................................................................. 5 133  2.1.4 Threat ........................................................................................................... 6 134  2.2 The Defense Side ...................................................................................................... 7 135  2.2.1 Risk ............................................................................................................... 7 136  2.2.2 Security Controls ........................................................................................... 7 137  2.2.3 Security Objectives ....................................................................................... 7 138  3. Introduction to System and Data-Centric System Threat Modeling ............................. 9 139  4. Basics of Data-Centric System Threat Modeling ..........................................................11 140  4.1 Step 1: Identify and Characterize the System and Data of Interest .......................... 11 141  4.2 Step 2: Identify and Select the Attack Vectors to Be Included in the Model ............. 13 142  4.3 Step 3: Characterize the Security Controls for Mitigating the Attack Vectors ........... 14 143  4.4 Step 4: Analyze the Threat Model ........................................................................... 16 144  4.5 Customizing the Data-Centric System Threat Modeling Approach .......................... 17 145  146  List of Appendices 147  Appendix A— Acronyms and Other Abbreviations ..............................................................19 148  Appendix B— References ......................................................................................................20 149  150  151  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  1  Executive Summary 152  Threat modeling is a form of risk assessment that models aspects of the attack and defense sides of a 153  particular logical entity, such as a piece of data, an application, a host, a system, or an environment. The 154  fundamental principle underlying threat modeling is that there are always limited resources for security 155  and it is necessary to determine how to use those limited resources effectively. There are many types of 156  threat modeling; for example, system threat modeling is threat modeling performed for operational 157  systems to improve their overall security. This publication focuses on one type of system threat modeling: 158  data-centric system threat modeling. Data-centric system threat modeling is threat modeling that is 159  focused on protecting particular types of data within systems. 160  Threat modeling is needed because of the dynamic nature of security. The attack and defense sides of 161  security are constantly changing. As part of handling this change, organizations should continually 162  reassess and evolve their defenses. This includes adopting continuous monitoring practices, security 163  automation technologies, and threat intelligence feeds to detect new vulnerabilities and attacks in near-164  real-time, allowing rapid risk mitigation. Another key component of handling the constant change in 165  security is having security metrics; these can be used for more informed decision making, again often 166  relating to risk management in general and risk mitigation in particular.  167  Increasingly, simply following general “best practices” for security is insufficient for safeguarding high-168  value data. Best practices are largely based on conventional wisdom intended to mitigate common threats 169  and vulnerabilities. By their very nature, such best practices are generalized, especially for ubiquitous 170  products (web browsers, server and desktop operating systems, etc.) They do not take into account the 171  unique characteristics of each system. Also, most best practices are geared toward preventing host 172  compromise and do not take into account the security needs for particular data (again, a more generalized 173  goal versus a specific one). So, for a particular situation, best practices may not include security controls 174  that are necessary to effectively reduce risk.  175  Data-centric system threat modeling allows organizations to consider the security needs of each case of 176  interest, instead of relying solely on generalized “best practice” recommendations. Organizations with 177  strong capabilities in continuous monitoring, security automation, and security metrics should consider 178  adding data-centric system threat modeling based on the principles presented in this publication to 179  supplement these capabilities and achieve demonstrably better security for data of particular importance.  180  181  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  2  1. Introduction 182  1.1 Purpose and Scope 183  Organizations often plan, implement, maintain, and assess the security controls for their systems without 184  performing a methodical analysis of risk involving system threat modeling. The purpose of this 185  publication is to provide information on the basics of system threat modeling so that organizations can 186  successfully use it as part of their risk management processes. 187  There are many forms of threat modeling. This publication’s scope is limited to data-centric system threat 188  modeling, which involves focusing on the security of particular instances of data (such as client 189  information stored on a field agent’s laptop) instead of focusing on the security of particular hosts, 190  operating systems (OS), applications, etc. 191  This publication provides a general methodology that organizations can use. The intent is not to replace 192  existing methodologies, but rather to define fundamental principles that should be part of any sound data-193  centric system threat modeling methodology. 194  1.2 Audience 195  This document is intended for security managers, security engineers/architects, system administrators, and 196  others who are responsible for planning, implementing, and maintaining data and system security 197  controls. Auditors and others who need to assess the security of data and systems may also find this 198  publication useful. 199  1.3 Document Structure 200  The remainder of this document is organized into the following major sections and appendices: 201  • Section 2 discusses attack and defense basics. The terminology and concepts defined in this 202  section are fundamental to understanding the rest of the publication. 203  • Section 3 provides an introduction to general system threat modeling. 204  • Section 4 presents a basic methodology for data-centric system threat modeling, with simplified 205  examples illustrating the use of the methodology. 206  • Appendix A contains an acronym and abbreviation list. 207  • Appendix B lists the references for the document. 208  209  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  3  2. Attack and Defense Basics 210  This section establishes a foundation for the rest of the document by covering the basic concepts of 211  security relevant to threat modeling. It defines fundamental terminology, such as what vulnerabilities and 212  attack vectors are, because of the lack of consensus in the security community as to what such terms 213  mean. It also explains how these concepts work in practice. The discussion is divided into two parts: the 214  attack side (Section 2.1) and the defense side (Section 2.2). This section can be thought of as explaining 215  the problem that threat modeling is trying to solve. The term “threat modeling” is defined in Section 3. 216  2.1 The Attack Side 217  This section defines the basic concepts related to the attack side of threat modeling, grouped by core 218  terms: vulnerability, exploit and attack, attack vector, and threat. Where applicable, it enumerates the 219  major categories of each entity (such as major categories of vulnerabilities). These enumerations are not 220  intended to be comprehensive or authoritative, but instead to help illustrate the potential scope of threat 221  modeling activities. 222  2.1.1 Vulnerability 223  The term “vulnerability” has been defined in many ways over years. This document proposes that a 224  vulnerability is any trust assumption involving people, processes, or technology that can be violated in 225  order to exploit a system. Types of vulnerabilities include the following: 226  • A software flaw vulnerability is caused by an error in the design or coding of software. One 227  example is an input validation error, such as user-provided input being trusted, and thus not being 228  properly evaluated for malicious character strings and overly long values associated with known 229  attacks. Another example is a race condition error that allows the attacker to perform a specific 230  action with elevated privileges. A race condition is possible because the software does not expect 231  certain patterns of activity to occur, in effect trusting that users will not cause such patterns. 232  • A security configuration issue vulnerability involves the use of security configuration settings 233  that negatively affect the security of the software if taken advantage of by users. A security 234  configuration setting is an element of a software’s security that can be altered through the 235  software itself. Examples of settings are an operating system offering access control lists that set 236  user privileges for files, and an application offering a setting to enable or disable the encryption 237  of sensitive data stored by the application. Many configuration settings increase security at the 238  expense of reducing functionality, so using the most secure settings could make the software 239  useless or unusable.  240  • A software feature is a functional capability provided by software. A software feature misuse 241  vulnerability is a vulnerability in which the feature also provides an avenue to compromise the 242  security of a system. These vulnerabilities are caused by the software designer making trust 243  assumptions that permit the software to provide beneficial features, while also introducing the 244  possibility of someone violating the trust assumptions to compromise security. For example, 245  email client software may contain a feature that renders HTML content in email messages. An 246  attacker could craft a fraudulent email message that contains hyperlinks that, when rendered in 247  HTML, appear to the recipient to be benign, but actually take the recipient to a malicious web site 248  when they are clicked on. One of the trust assumptions in the design of the HTML content 249  rendering feature was that users would not receive malicious hyperlinks and click on them. 250  Another example of a software feature misuse vulnerability is an attacker stealing a user’s 251  credentials and reusing them to impersonate the user; the trust assumption was that only the 252  legitimate user would use those credentials. Misuse vulnerabilities are inherent in software 253  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  4  features because each feature is based on trust assumptions—and those assumptions can be 254  broken, albeit involving significant cost and effort in some cases. [1] 255  No system is 100 percent secure: every system has vulnerabilities. At any given time, a system may not 256  have any known software flaws, but security configuration issues and software feature misuse 257  vulnerabilities are always present and cannot even be readily enumerated at this time. A system’s 258  vulnerabilities are likely to have a wide variety of characteristics. Some will be very easy to exploit, while 259  others will only be exploitable under a combination of highly unlikely conditions. One vulnerability 260  might provide root-level access to a system, while another vulnerability might only permit read access to 261  an insignificant file. 262  2.1.2 Exploit and Attack 263  To exploit a vulnerability is to use it to violate security objectives, such as confidentiality, integrity, and 264  availability (see Section 2.2.3 for more information on security objectives). The program code or other 265  commands used to exploit a vulnerability are generically referred to as an exploit or an attack. These 266  meanings, which are specific to the commands, are not to be confused with the verb forms of “exploit” 267  and “attack”, which have different meanings; “to exploit” implies a successful security violation, while 268  “to attack” implies an attempted security violation but not its success or failure. Noun forms of these 269  verbs, referring to the actions, have the same distinction in meanings; an attack (action) that succeeds can 270  also be called an exploit. 271  This document uses the term attacker to refer to a party who attacks a host, network, or other IT resource. 272  However, not all attacks are intentional. Some attacks are performed by users who accidentally or 273  otherwise unintentionally violate security policies, requirements, etc., to the point of compromising 274  security. Because intent often has no relation to the impact of a compromise, this document uses the term 275  “attack” to refer to both intentional and inadvertent compromises. Sections 2.1.2.1 and 2.1.2.2 discuss the 276  individuals who perform attacks in both categories. 277  2.1.2.1 Intentional 278  Attackers who intend to exploit vulnerabilities are motivated by various reasons, ranging from the desire 279  to make political or social statements to financial gain and cyberwarfare. Some attackers are focused on a 280  short-term action, such as a financial transaction, but many attackers, especially those interested in 281  gaining access to sensitive information, may be more interested in long-term infiltration and data 282  gathering. These attacks are often targeted, such as focusing on exploiting a high-value system or 283  individual. 284  The skill sets of attackers vary as widely as their motivations. At one extreme are unskilled individuals 285  who purchase attack toolkits that make basic exploitation almost trivial to perform. At the other extreme 286  are highly skilled individuals who are capable of discovering new vulnerabilities on their own and 287  figuring out how to exploit them. Another important group of attackers to consider is malicious insiders; 288  even though they may not be particularly skilled in exploitation, their level of access and detailed 289  knowledge of the organization’s systems makes them particularly effective at data theft and manipulation. 290  A malicious insider may also work in conjunction with an external attacker, such as insiders selling their 291  usernames and passwords to third parties. 292  Another category of intentional attacks is not directly associated with a particular person or group—for 293  example, malware may have been propagating from system to system for some time and is not being 294  directed or otherwise controlled by anyone. This is not meant to imply that no one is responsible for the 295  malware, but rather that there is not a person specifically launching each instance of the malware. 296  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  5  Because the malware is designed to exploit vulnerabilities, this publication considers all malware-based 297  attacks to be intentional attacks. 298  2.1.2.2 Inadvertent 299  Attackers who inadvertently exploit vulnerabilities are acting either by accident or through a lack of 300  understanding, such as performing actions that they do not know are security violations or do not consider 301  a “real” security problem. 302  2.1.3 Attack Vector 303  An attack vector is a segment of the entire pathway that an attack uses to access a vulnerability. Each 304  attack vector can be thought of as comprising a source of malicious content, a potentially vulnerable 305  processor of that malicious content, and the nature of the malicious content itself. Examples of attack 306  vectors are: 307  • Malicious web page content (content) downloaded from a web site (source) by a vulnerable web 308  browser (processor); 309  • A malicious email attachment (content) in an email client (source) rendered by a vulnerable 310  helper application (processor); 311  • A malicious email attachment (content) downloaded from an email server (source) to a vulnerable 312  email client (processor); 313  • A network service with inherent vulnerabilities (processor) used maliciously (content) by an 314  external endpoint (source); 315  • Social engineering-based conversation (content) performed by phone from a human attacker 316  (source) to get a username and password from a vulnerable user (processor); 317  • Stolen user credentials (content) typed in by an attacker (source) to a web interface for an 318  enterprise authentication system (processor); and 319  • Personal information about a user harvested from social media (content) entered into a password 320  reset website by an attacker (source) to reset a password by taking advantage of weak password 321  reset processes (processor). 322  The characteristics of attacks vary widely. Some involve exploitation of a single vulnerability using a 323  single attack vector, while others involve multiple vulnerabilities and multiple attack vectors, or even a 324  single vulnerability and multiple attack vectors. And the vulnerabilities and attack vectors may be spread 325  across multiple hosts, compromising one host in order to compromise another, further complicating the 326  composition of an attack.  327  Here is an example of a single possible attack involving one vulnerability, decomposed into its attack 328  vectors: 329  1. Malicious email attachment (content) sent from a host (source) to the organization’s primary mail 330  server (processor); 331  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  6  2. Malicious email attachment (content) sent from the organization’s primary mail server (source) to 332  antivirus server (processor); 333  3. Malicious email attachment (content) sent from the antivirus server (source) to the organization’s 334  internal mail server (processor); 335  4. Malicious email attachment (content) sent from the organization’s internal mail server (source) to 336  the user’s email client (processor); and 337  5. Malicious email attachment (content) rendered (processor) by the vulnerable email client 338  (source). 339  Note that although there are five attack vectors, the actual exploitation only occurs during the last of the 340  five (when the malicious attachment is rendered by a vulnerable email client). However, each attack 341  vector affords an opportunity to detect and stop the attack before it goes any farther. 342  Although this example focuses on vulnerabilities in technologies, many attacks include non-technological 343  attack vectors. For example, attackers often use social engineering methods to trick users into revealing 344  their passwords, performing actions that unknowingly grant attackers remote access to systems, and 345  otherwise enabling security to be compromised. Similar attacks may be performed on IT personnel, such 346  as an attacker impersonating a legitimate user and convincing a help desk agent to reset the user’s 347  password to a password selected by the attacker. 348  Because the focus of this publication is modeling threats against a targeted (vulnerable) system, the 349  compromises of greatest interest are those against the ultimate target itself. There are often intermediate 350  hosts used as jumping off points for attacks—in botnets, for example. Analyzing how those intermediate 351  hosts become compromised would fall within the scope of performing an analysis of those individual 352  intermediate hosts themselves as targets, and is outside the scope of analyzing the ultimate target. So, in 353  the previous example with five attack vectors, with the ultimate target being the host with the vulnerable 354  email client, it would be irrelevant to the target how the host in step 1 that originally sent the malicious 355  email attachment was compromised. 356  Other terms are useful when discussing attack vectors. For example, an attack model comprises a scenario 357  that may occur and a single path (one or more attack vectors in sequence) that could be taken for that 358  scenario. The attack models for a scenario and the security controls attempting to disrupt those attack 359  models collectively constitute a threat model.1 Another way to analyze attack vectors is to analyze all of 360  the attack vectors directly against a particular system; this is known as the system’s attack surface. 361  2.1.4 Threat 362  A threat is defined in NIST Special Publication (SP) 800-30 as “any circumstance or event with the 363  potential to adversely impact organizational operations and assets, individuals, other organizations, or the 364  Nation through an information system via unauthorized access, destruction, disclosure, or modification of 365  information, and/or denial of service.” [2, p. B-13] Threats may be intentional or unintentional. A threat 366  source is the cause of a threat, such as a hostile cyber or physical attack, a human error of omission or 367  commission, a failure of organization-controlled hardware or software, or other failure beyond the control 368  of the organization.  369  1  Section 3 contains a more formal definition of the term “threat modeling.”  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  7  A threat event is defined in NIST SP 800-30 as “an event or situation initiated or caused by a threat 370  source that has the potential for causing adverse impact.” [2, p. B-13] The distinction between a threat and 371  a threat event is subtle, but basically a threat event is caused by a particular threat source, while a threat is 372  more generic (not caused by a particular threat source). 373  2.2 The Defense Side 374  This section explains the basic concepts related to the defense side of threat modeling, grouped by core 375  terms: risk, security controls, and security objectives.  376  2.2.1 Risk 377  Committee on National Security Systems Instruction (CNSSI) 4009, National Information Assurance (IA) 378  Glossary, defines risk in general as “a measure of the extent to which an entity is threatened by a potential 379  circumstance or event, and typically a function of: (i) the adverse impacts that would arise if the 380  circumstance or event occurs; and (ii) the likelihood of occurrence” [3, p. 104] and information security 381  risks specifically as “those risks that arise from the loss of confidentiality, integrity, or availability of 382  information or information systems and reflect the potential adverse impacts to organizational operations 383  (including mission, functions, image, or reputation), organizational assets, individuals, other 384  organizations, and the Nation” [3, p. 65]. 385  Risk management is defined in CNSSI 4009  as “the program and supporting processes to manage 386  information security risk to organizational operations….” [3, p. 104]. Part of risk management is risk 387  assessment, which is defined in NIST SP 800-30 as “the process of identifying, prioritizing, and 388  estimating risks to organizational operations (including mission, functions, image, reputation), 389  organizational assets, individuals, other organizations, and the Nation, resulting from the operation of an 390  information system” [2, p. B-9]. Risk assessment considers the possible threats and vulnerabilities, and 391  determines what security controls (see Section 2.2.2) should be used to mitigate them, which means to 392  reduce their risk to an acceptable level. 393  2.2.2 Security Controls 394  CNSSI 4009 defines security controls as “the management, operational, and technical controls (i.e., 395  safeguards or countermeasures) prescribed for an information system to protect the confidentiality, 396  integrity, and availability of the system and its information” [3, p. 110]. Although technical controls can 397  be fully automated, which makes them an obvious choice for stopping attacks, management and 398  operational controls also play important roles. For example, users must be trained on their security 399  responsibilities so that they are less likely to violate security policies, be tricked by phishing attacks, and 400  otherwise decrease the organization’s security posture. Ultimately an organization’s security relies on a 401  combination of people, processes, and technology. 402  2.2.3 Security Objectives 403  Organizations usually think of their security objectives for data in terms of protecting its confidentiality2, 404  integrity, and/or availability.3 In many cases, the security objectives for an instance of data should not all 405  have equal importance, and in some cases, an organization may want to focus its threat modeling efforts 406  2  For the purposes of this publication, privacy objectives will be considered a subset of confidentiality objectives.  3  Some organizations may choose to replace the security objectives with one or more security requirements for threat  modeling purposes. Security requirements are more specific and granular than security objectives, and they often come  directly from the organization’s policies or from regulations or security compliance initiatives that the organization is  subject to.  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  8  on a single objective. For example, if a risk assessment shows that the risk of a breach of confidentiality is 407  unacceptably high, then performing threat modeling for confidentiality only may be most helpful for 408  mitigating the confidentiality breach risk to an acceptable level. Similarly, information that has already 409  been released to the public may still need its integrity and availability protected, but not its 410  confidentiality. 411  Because this publication is addressing data-centric system threat modeling, only security objectives for 412  data—not systems—are pertinent. This means that operational unavailability of systems caused by attacks 413  is out of scope, for example, while operational unavailability of data caused by attacks is in scope.  414  The security objectives relate directly to the risk management, assessment, mitigation, and security 415  control concepts discussed in Sections 2.2.1 and 2.2.2. For example, if the results of risk assessment show 416  that the risk of a breach of confidentiality is unacceptably high, then additional security controls or 417  changes to existing security controls may be needed to mitigate the confidentiality breach risk to an 418  acceptable level. The same is true for integrity and availability. 419  420  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  9  3. Introduction to System and Data-Centric System Threat Modeling 421  This section provides an overview of threat modeling in general, with an emphasis on system and data-422  centric system threat modeling. Threat modeling is a form of risk assessment that models aspects of the 423  attack and defense sides of a particular logical entity, such as a piece of data, an application, a host, a 424  system, or an environment. The fundamental principle underlying threat modeling is that there are always 425  limited resources for security and it is necessary to determine how to use those limited resources 426  effectively. 427  There are many types of threat modeling, and they can be distinguished based on three related 428  characteristics: 429  1. The logical entity being modeled (data, software, system, etc.); 430  2. The phase of the system lifecycle (for example, modeling security for software during its initial 431  design versus modeling security for already-implemented off-the-shelf software, for example); 432  and 433  3. The goal of the threat modeling (to reduce software vulnerabilities, to thwart particular classes of 434  attackers, to improve overall system security, to protect particular types of data, etc.). 435  A common form of threat modeling is software threat modeling, which is threat modeling performed 436  during software design to reduce software vulnerabilities. There are many established methodologies for 437  performing software threat modeling.  438  Another common form of threat modeling is known as system threat modeling, which is threat modeling 439  performed for operational systems to improve their overall security. Compared to software threat 440  modeling, system threat modeling tends to be largely informal and ad hoc.  441  Data-centric system threat modeling is a particular type of system threat modeling, and its basics are 442  described in Section 4. This type of threat modeling is focused on protecting particular types of data 443  within systems. 444  Threat modeling is needed because of the dynamic nature of security. Security would be difficult enough 445  to tackle if it was a one-time endeavor. Unfortunately, the attack side is constantly changing; new 446  vulnerabilities are discovered, new attacks are created, and new threats arise. Long-term changes happen, 447  too—new classes of vulnerabilities are discovered, attacker motivations change, and other 448  transformations occur over years. The defense side of security is also constantly changing—security 449  controls are improved and enhanced, new types of security controls are developed, etc. Change is 450  inevitable; as a particular class of vulnerabilities becomes well mitigated, for example, attackers simply 451  identify another class of vulnerabilities that are not as well mitigated to exploit, and defenders adjust 452  security controls accordingly. 453  As part of handling this constant change, organizations should continually reassess and evolve their 454  defenses. This includes adopting continuous monitoring practices [4], security automation technologies 455  [5], and threat intelligence feeds to detect new vulnerabilities and attack attempts in near-real-time, 456  allowing rapid risk mitigation. Another key component of handling the constant change in security is 457  having security metrics; these can be used for more informed decision making, again often relating to risk 458  management in general and risk mitigation in particular.  459  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  10  Organizations with strong capabilities in continuous monitoring, security automation, and security metrics 460  should consider adding data-centric system threat modeling as described in Section 4 to supplement these 461  capabilities and achieve demonstrably better security for data of particular interest. Quantitative security 462  metrics are more accurate than qualitative ones, but quantitative metrics are presently very difficult for 463  most organizations to collect. Using high-quality qualitative metrics is far better than using no metrics at 464  all. 465  Increasingly, simply following general “best practices” for security is insufficient for safeguarding high-466  value data. Best practices are largely based on conventional wisdom intended to mitigate common threats 467  and vulnerabilities. By their very nature, such best practices are generalized, especially for ubiquitous 468  products (web browsers, server and desktop operating systems, etc.) They do not take into account the 469  unique characteristics of each system. Also, most best practices are geared toward preventing host 470  compromise and do not take into account the security needs for particular data (again, a more generalized 471  goal versus a specific one). So, for a particular situation, best practices may omit security controls that are 472  necessary to effectively reduce risk.  473  Data-centric system threat modeling allows organizations to consider the security needs of each case of 474  interest, instead of relying solely on “best practice” generalized recommendations. Organizations are 475  already very familiar with applying best practices to operating systems and individual applications, such 476  as securing a web server (host) or web server software. What is considerably more challenging for 477  organizations to tackle is determining how to secure a particular chunk of data. It is not that securing a 478  piece of data is so difficult, but that traditionally security professionals, system administrators, and others 479  responsible for securing operational systems have focused on securing systems, not data. The rest of this 480  publication focuses on data security. 481  This differentiation between system and data security has parallels to existing NIST publications. A 482  system security approach starts with a FIPS 199 [6] low/moderate/high impact rating for a system, and 483  then selects the corresponding security controls from NIST SP 800-53 [7]. In contrast, a data security 484  approach starts with a publication such as NIST SP 800-60 [8] for categorizing the type of information. 485  486  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  11  4. Basics of Data-Centric System Threat Modeling 487  Data-centric system threat modeling brings together the attack and defense side information for data of 488  interest in a standardized model that facilitates security analysis, decision making, and change planning. 489  This section provides information on the fundamentals of data-centric system threat modeling. This 490  publication is not trying to define a new threat modeling methodology, but rather to educate organizations 491  on the fundamentals of data-centric system threat modeling and to make recommendations related to the 492  use of this type of modeling. 493  The data-centric system threat modeling approach presented in this publication has four major steps: 494  1. Identify and characterize the system and data of interest; 495  2. Identify and select the attack vectors to be included in the model; 496  3. Characterize the security controls for mitigating the attack vectors; and 497  4. Analyze the threat model. 498  Sections 4.1 through 4.4 provide more information on performing each of these steps. Each step is also 499  illustrated by examples, which are denoted by a border around the text. The same example is continued 500  throughout all of the steps. Note that the data presented in the example is hypothetical and meant solely 501  for providing a simplified illustration of the steps. 502  Section 4.5 explains in detail that this approach to data-centric system threat modeling is intended to be 503  customized to meet the needs of each organization, and it shows how easily this customization can occur.  504  4.1 Step 1: Identify and Characterize the System and Data of Interest 505  The first step is to identify and characterize the system and data of interest. The system and data should be 506  defined narrowly, pertaining to a particular logical set of data on a particular host or small group of 507  closely related hosts and devices.  508  Once the system and data are defined, they need to be characterized, which refers to understanding the 509  system’s operation and usage to the extent needed for the organization’s data-centric system threat 510  modeling approach. At an absolute minimum, characterization should include the following: 511  • The authorized locations for the data within the system.4 This will include some or all of the 512  following: 513  o Storage: all places where data may be at rest within the system boundaries; 514  o Transmission: all ways in which data may transit over networks between system components 515  and across the system’s boundaries; 516  o Execution environment: e.g., data held in local memory during runtime, data processed by 517  virtual CPUs, etc.; 518  o Input: e.g., data typed in using the keyboard; and 519  4  The methodology identifies just the authorized locations because someone with access to the data could store, transmit,  output, or otherwise place the data in any accessible location, authorized or not, including locations outside the system  boundaries.  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  12  o Output: e.g., data printed to a physically attached printer, data displayed on the laptop screen, 520  etc. 521  • A basic understanding of how the data moves within the system between authorized 522  locations. For example, a file might be held in memory while it is being created and is only 523  written out to storage when the user directs the system to do so. Depending on the complexity of 524  the system, gaining this understanding may require first understanding the system’s functions and 525  processes, users and usage scenarios, workflows, trust assumptions, and other aspects of people, 526  processes, and technology related to the system. 527  • The security objectives (e.g., confidentiality, integrity, availability) for the data. In many 528  cases, some objectives are more important than others; in other cases, an organization may want 529  to focus on a single objective for a particular threat model.5 530  • The people and processes who are authorized to access the data in a way that could affect 531  the security objectives. For example, if an organization has selected confidentiality as its sole 532  objective for a particular threat model, the authorized people and processes should include all 533  users, administrators, applications, services, etc. who are allowed to read the data. 534  Example Scenario 535  Summary: The data of interest is a spreadsheet containing personally identifiable information (PII) for 536  employees who have received workers’ compensation.  537  The system of interest comprises: 538  • a human resource specialist’s laptop (spreadsheet is stored on and used from the laptop); 539  • a USB flash drive (spreadsheet is backed up onto the USB flash drive); and 540  • a printer (spreadsheet can be printed from the laptop to the printer). 541  The authorized locations for the data of interest are as follows: 542  • Storage: Spreadsheet kept on a laptop hard drive, backup of spreadsheet kept on a USB flash drive; 543  • Transmission: Sent to a printer over a wireless network; 544  • Execution environment: Local laptop memory and processors; 545  • Input: Typed in using the laptop keyboard; and 546  • Output: Displayed to the screen. 547  548  Description: Data is input through the keyboard into the spreadsheet, which is temporarily held in the 549  execution environment. As the user updates the spreadsheet, the data is displayed to the screen. When the 550  user has completed editing the spreadsheet, the user directs the system to save the spreadsheet to the 551  laptop hard drive. The user may also load the spreadsheet into the execution environment and print the 552  spreadsheet to a nearby printer through a wireless network connection. Finally, the user occasionally 553  copies the latest version of the spreadsheet from the laptop hard drive to a USB flash drive as a backup. 554  5  Some organizations may choose to replace the security objectives with one or more security requirements. Security  requirements are more specific and granular than security objectives, and they often come directly from the organization’s  policies or from regulations or security compliance initiatives that the organization is subject to.  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  13  Although confidentiality, integrity, and availability all matter for the data of interest, confidentiality is 555  considered so much more important that the organization has decided to perform its trust modeling in 556  terms of confidentiality only. 557  In this highly simplified example, the human resource specialist is the only person who is authorized to 558  access the data. 559  4.2 Step 2: Identify and Select the Attack Vectors to Be Included in the Model 560  The second step involves identifying the potential attack vectors, as discussed in Section 2.1.3, that could 561  be used to negatively impact one or more of the identified security objectives for one of the authorized 562  locations for the data. Once the attack vectors are identified, it may be necessary to select only a subset of 563  those attack vectors to be included in the threat model. Although it is generally preferable to include all 564  the attack vectors, there are often too many to be addressed with limited resources. Possible criteria to 565  consider include the relative likelihood of the attack vector being used and the most likely impact of a 566  successful attack. See Section 4.5 below for more information on the selection process. 567  Location 1: Stored in a spreadsheet on the local hard drive. 568  • Vector 1a: Attacker gains unauthorized physical access to the laptop, uses forensic tools or other 569  utilities to copy the file (without authenticating to the OS). 570  • Vector 1b: Attacker gains unauthorized physical access to the laptop, exploits vulnerabilities to gain 571  OS access (impersonating user/admin). 572  • Vector 1c: Attacker steals and reuses user/admin/service credentials. 573  • Vector 1d: Attacker gains access to/control over user’s session/device. 574  • Vector 1e: User forwards the file to an unauthorized recipient (user was tricked via social 575  engineering, user is malicious, user made a mistake, etc.). 576  • Vector 1f: Attacker accesses unsecured network service (e.g., connects to unsecured file share) and 577  gains access to the file. 578  579  Location 2: Stored in a spreadsheet on a flash drive backup. 580  • Vector 2a: Attacker gains unauthorized physical access to the flash drive, mounts the drive and 581  copies the file. 582  • Vector 2b: Attacker steals and reuses user/admin/service credentials for laptop while flash drive is 583  mounted.  584  • Vector 2c: Attacker gains access to/control over user’s session/device while flash drive is mounted.  585  • Vector 2d: User forwards the file to an unauthorized recipient.  586  587  Location 3: Printed to a nearby printer over a wireless network connection. 588  • Vector 3a: Attacker monitors unencrypted or weakly encrypted wireless network communications 589  and captures the data being sent to the printer. 590  • Vector 3b: Attacker views a printout of the spreadsheet. 591  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  14  592  Location 4: Processed locally. 593  • Vector 4a: Attacker gains access to/control over user’s session/device. 594  595  Location 5: Input locally. 596  • Vector 5a: Attacker watches the information being typed in to the laptop. 597  • Vector 5b: Attacker uses keystroke logger on laptop to monitor keystrokes. 598  599  Location 6: Output locally. 600  • Vector 6a: Attacker views the information on the laptop screen. 601  • Vector 6b: Attacker uses malware on laptop to take screen shots. 602  603  Selected attack vectors (based on the possibility and the likelihood of each attack vector being used to 604  completely compromise confidentiality): 605  o Vector 1c: Data is stored in a spreadsheet on the local hard drive; attacker steals and reuses 606  user/admin/service credentials. 607  o Vector 1d: Data is stored in a spreadsheet on the local hard drive; attacker gains access to/control 608  over user’s session/device. 609  o Vector 2b: Data is stored in a spreadsheet on a flash drive backup; attacker steals and reuses 610  user/admin/service credentials for laptop while flash drive is mounted. 611  o Vector 2c: Data is stored in a spreadsheet on a flash drive backup; attacker gains access to/control 612  over user’s session/device while flash drive is mounted. 613  o Vector 4a: Data is processed locally; attacker gains access to/control over user’s session/device. 614  615  4.3 Step 3: Characterize the Security Controls for Mitigating the Attack Vectors 616  The third step of the methodology is, for each attack vector selected in Step 2, to identify and document 617  security control alterations (additions to existing security controls, reconfigurations of existing security 618  controls, etc.) that would help mitigate the risk associated with the attack vector and that are reasonably 619  feasible to accomplish. Note that it is not necessarily to enumerate every single applicable control, such as 620  having a security program and policies, because these controls should already be in place for the entire 621  enterprise and are not normally customized to take a particular attack vector into consideration. 622  Next, for each selected security control alteration, estimate how effectively it would address exploitation 623  of each applicable attack vector. This could be as simple as ranking effectiveness as low, medium, or 624  high, or as complex as estimating the percentage of attacks against the attack vector that would be stopped 625  by this mitigation. Whatever method is selected, it should be comparable across mitigations and attack 626  vectors. 627  The counterpart to estimating the effectiveness of each security control alteration is estimating the 628  negative implications. Factors to consider may include cost (perhaps the order of magnitude or the range 629  of costs for acquisition and implementation, and for annual management/maintenance) and reductions in 630  functionality, usability, and performance. These can be particularly hard to determine accurately for 631  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  15  future mitigations, so it may be necessary to develop very rough estimates for them using a simple 632  low/medium/high type scale that is particular to the organization. 633  Feasible security control alterations: 634  1. Require strong password with strongly encrypted password hash (vectors 1c and 2b). 635  • Effectiveness: Low  636  • Acquisition and implementation costs: Low 637  • Annual management/maintenance costs: Low 638  • Impact on functionality: Low 639  • Impact on usability: Low 640  • Impact on performance: Low 641  642  2. Require multifactor authentication (vectors 1c and 2b) 643  • Effectiveness: High  644  • Acquisition and implementation costs: Moderate 645  • Annual management/maintenance costs: Moderate 646  • Impact on functionality: Low 647  • Impact on usability: Moderate 648  • Impact on performance: Low 649  650  3. Use antivirus software, spam filtering, real-time blacklists, user awareness, web reputation software, 651  etc. (vectors 1c, 1d, 2b, 2c, and 4a) 652  • Effectiveness: Moderate 653  • Acquisition and implementation costs: Moderate 654  • Annual management/maintenance costs: Moderate 655  • Impact on functionality: Moderate 656  • Impact on usability: Moderate 657  • Impact on performance: Moderate 658  659  4. Patch vulnerabilities (vectors 1c, 1d, 2b, 2c, and 4a) 660  • Effectiveness: Low 661  • Acquisition and implementation costs: Moderate 662  • Annual management/maintenance costs: Moderate 663  • Impact on functionality: Moderate 664  • Impact on usability: Low 665  • Impact on performance: Moderate 666  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  16  667  4.4 Step 4: Analyze the Threat Model 668  The final step of the methodology is to analyze all the characteristics documented during the previous 669  steps, which collectively comprise the threat model, to assist in evaluating the effectiveness and efficiency 670  of each security control option against the selected attack vectors. It is far too simplistic to say that a 671  control should be applied because it lowers risk. In addition to their financial costs in terms of acquisition, 672  implementation, and management/maintenance, security controls can negatively impact functionality, 673  usability, and performance, among other factors. Any assessment of security controls should include 674  considerations of all significant relevant factors. 675  The most challenging part of threat model analysis is determining how to consider all of these 676  characteristics together. It is straightforward to compare an individual characteristic, such as the annual 677  management/maintenance costs, across attack vectors and mitigations. However, it is not straightforward 678  at all to compare the entire set of characteristics for an attack vector against the entire set of 679  characteristics for another attack vector. Yet such comparisons are absolutely critical to determining how 680  risk can best be reduced across all the attack vectors, in a cost-effective manner that has an acceptable 681  negative impact on the organization’s operations. Each organization needs to determine how to compare 682  the characteristics for each attack vector/security control pair, as a basis for comparing attack vector 683  characteristics and security control characteristics. 684  One approach to facilitating these comparisons is to assign scores and weightings to each characteristic. 685  For example, the narrative descriptions of threat consequence could be converted to numerical values on a 686  three-point scale. Three-point scales could also be used for other characteristics in place of low, medium, 687  and high ratings. Even complex characteristics, such as cost, could be mapped to a simple scale. 688  In addition to assigning scores to each characteristic’s possible values or value ranges, the organization 689  also needs to consider the relative weights of each characteristic. Perhaps the effectiveness against attacks 690  is considered much more important than other characteristics; if so, this could be conveyed by doubling or 691  tripling its score. Similarly, all other characteristics could be assigned a multiplier that would increase or 692  decrease their scores or keep them the same. Then after applying the multipliers, the organization would 693  add up the results and have a relative score for each attack vector/security control pair.  694  Another scoring approach that could be followed in addition to the previously described approach is to set 695  thresholds or rules for certain criteria and eliminate from further consideration any attack vector/security 696  control pairs that do not meet these. A simple example is eliminating all pairs that have a cost of $100,000 697  or more over a period of three years. A more complex example is eliminating all pairs that have a cost of 698  $50,000 or more over a period of three years AND a high impact on usability AND low or medium 699  effectiveness against attacks. 700  After much debate, the organization decides to set the following scores for the characteristics and weigh 701  them all evenly: 702  • No security control effectiveness = 0 703  • Security control effectiveness of low = 1 704  • Security control effectiveness of moderate = 2 705  • Security control effectiveness of high = 3 706  • Negative implication of high = 1 707  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  17  • Negative implication of moderate = 2 708  • Negative implication of low = 3 709  The organization calculates the total of the negative implication scores for each security control (see first 710  table below), then multiplies these totals by the score of the security control effectiveness per attack 711  vector (see second table below) to reach a score for each attack vector/security control pair (see shaded 712  area of the second table below). The higher the score, the more “bang for the buck” the security control 713  will provide against the corresponding attack vector. This information is now ready for use in decision 714  making. 715  716  Possible Security Controls  A cq  ui si  tio n  an d  Im pl  em en  ta tio  n  C  os ts  A nn  ua l M  an ag  em en  t/  M  ai nt  en an  ce  C  os ts  Im pa  ct  o  n  Fu  nc tio  na lit  y  Im pa  ct  o  n  U  sa bi  lit y  Im pa  ct  o  n  Pe  rf or  m an  ce  To ta  l f or  S ec  ur ity  C  on tr  ol  Require strong password with strongly encrypted password  hash 3 3 3 3 3 15  Require multifactor authentication 2 2 3 2 3 12  Use antivirus software, spam filtering, real-time blacklists, user  awareness, web reputation software, etc. 2 2 2 2 2 10  Patch vulnerabilities 2 2 2 3 2 11  717  Possible Security Controls  Security Control  Effectiveness Per  Attack Vector  Negative  Implication  Total  Security Control Effectiveness  Times Negative Implication Total  Per Attack Vector  1c 1d 2b 2c 4a 1c 1d 2b 2c 4a  Require strong password with  strongly encrypted password  hash  1 0 1 0 0 15 15 0 15 0 0  Require multifactor  authentication 3 0 3 0 0 12 36 0 36 0 0  Use antivirus software, spam  filtering, real-time blacklists,  user awareness, web  reputation software, etc.  2 2 2 2 2 10 20 20 20 20 20  Patch vulnerabilities 1 1 1 1 1 11 11 11 11 11 11  718  4.5 Customizing the Data-Centric System Threat Modeling Approach 719  This publication presents a primarily qualitative approach to data-centric system threat modeling. A 720  quantitative approach would lead to more precise and accurate results than a qualitative approach, but 721  quantitative approaches would also be much more resource-intensive and would not scale well for 722  modeling large and complex systems unless the metrics and methodologies are mostly automated. 723  Because such automation is not yet widely available, if at all, this publication focuses on qualitative 724  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  18  modeling, which is still quite beneficial. In the future, as more automated quantitative metrics and 725  methodologies become available, organizations should reconsider the feasibility of using quantitative 726  modeling. 727  Most of the actions within the methodology can be addressed in a wide variety of ways in terms of both 728  content (what information is captured) and format/structure (how that information is captured). There is 729  no “right” method, and the examples are purely illustrative. What is important is recording sufficient 730  information to provide the necessary input for subsequent steps and a basis for making actionable 731  recommendations. 732  A prime example of the flexibility of the methodology is Step 2. Step 2 uses the list from Step 1 of 733  authorized locations for the data of interest. In the example, each attack vector is defined in a narrative 734  way, such as “Attacker gains unauthorized physical access to the laptop, uses forensic tools or other 735  utilities to copy the file (without authenticating to the OS).” This single statement actually conveys three 736  pieces of data: 1) a source of malicious content, 2) a potentially vulnerable processor of that malicious 737  content, and 3) the nature of the malicious content itself.  738  Some organizations may prefer a more narrative approach to defining attack vectors because it is easier 739  for others to understand, while other organizations may want a more thorough or technically-based 740  approach and therefore want to go through the threat consequences and actions as a taxonomy for 741  identifying the attack vectors. And, of course, there are many other ways of defining attack vectors that 742  individual organizations may prefer to use because of existing processes and tools or for other reasons. 743  Another factor to consider is the granularity of the attack vectors; one organization may only have the 744  resources to consider the attack vectors at a truly high level, while another organization may want to do a 745  deep dive and make the attack vectors as narrow as possible. 746  Organizations may also want to scope their threat modeling so it takes less effort. Using Step 2 as an 747  example, an organization may decide to eliminate any attack vectors that do not merit further 748  consideration. For example, an organization may decide that attack vectors with the lowest relative 749  likelihood should be ignored because there are far too many other attack vectors to be considered. 750  Similarly, an organization may only be interested (at least initially) in attack vectors that are likely to lead 751  to a complete compromise of confidentiality, integrity, and availability. Another possibility is to eliminate 752  attack vectors that do not have any feasible mitigations. Ideally an organization should analyze all attack 753  vectors before winnowing out any—for example, an unlikely attack vector may turn out to be incredibly 754  easy and inexpensive to mitigate, or a single mitigation may address multiple attack vectors—but 755  realistically this may not be feasible in some cases. 756  Of course, an organization can skip any of the elements of the methodology that are not relevant for a 757  particular situation or environment, and likewise an organization can add characteristics if other factors 758  are also important to the organization. 759  760  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  19  Appendix A—Acronyms and Other Abbreviations 761  Selected acronyms and other abbreviations used in the guide are defined below. 762  CMSS Common Misuse Scoring System  CNSSI Committee on National Security Systems Instruction  FIPS Federal Information Processing Standard  FISMA  Federal Information Security Modernization Act  FOIA Freedom of Information Act  HTML Hypertext Markup Language  IA Information Assurance  IR Interagency Report  IT  Information Technology  ITL Information Technology Laboratory  NIST  National Institute of Standards and Technology  OMB  Office of Management and Budget  OS Operating System  PII Personally Identifiable Information  RFC Request for Comments  SCAP Security Content Automation Protocol  SP  Special Publication  USB Universal Serial Bus  763  764  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  20  Appendix B—References 765  This appendix lists the references for the document. 766  [1] E. LeMay, K. Scarfone, and P. Mell, National Institute of Standards and Technology (NIST)  Interagency Report (IR) 7864, The Common Misuse Scoring System (CMSS): Metrics for  Software Feature Misuse Vulnerabilities, July 2012. http://dx.doi.org/10.6028/NIST.IR.7864  [2] Joint Task Force Transformation Initiative, National Institute of Standards and Technology  (NIST) Special Publication (SP) 800-30 Revision 1, Guide for Conducting Risk Assessments,  September 2012. http://dx.doi.org/10.6028/NIST.SP.800-30r1  [3] Committee on National Security Systems (CNSS), CNSS Instruction No. 4009, National  Information Assurance (IA) Glossary, April 6, 2015.  https://www.cnss.gov/CNSS/issuances/Instructions.cfm  [4] K. Dempsey, N. Chawla, A. Johnson, R. Johnston, A. Jones, A. Orebaugh, M. Scholl, and K.  Stine, National Institute of Standards and Technology (NIST) Special Publication (SP) 800- 137, Information Security Continuous Monitoring (ISCM) for Federal Information Systems and  Organizations, September 2011. http://dx.doi.org/10.6028/NIST.SP.800-137  [5] S. Quinn, K. Scarfone, and D. Waltermire, National Institute of Standards and Technology  (NIST) Special Publication (SP) 800-117 Revision 1 (Draft), Guide to Adopting and Using the  Security Content Automation Protocol (SCAP) Version 1.2, January 2012.  http://csrc.nist.gov/publications/PubsSPs.html#800-117-R1  [6] National Institute of Standards and Technology (NIST) Federal Information Processing  Standard (FIPS) Publication (PUB) 199, Standards for Security Categorization of Federal  Information and Information Systems, February 2004.  http://csrc.nist.gov/publications/fips/fips199/FIPS-PUB-199-final.pdf  [7] Joint Task Force Transformation Initiative, National Institute of Standards and Technology  (NIST) Special Publication (SP) 800-53 Revision 4, Security and Privacy Controls for Federal  Information Systems and Organizations, April 2013 (including updates as of January 22, 2015).  http://dx.doi.org/10.6028/NIST.SP.800-53r4  [8] K. Stine, R. Kissel, W. Barker, J. Fahlsing, and J. Gulick, National Institute of Standards and  Technology (NIST) Special Publication (SP) 800-60 Revision 1, Volume 1: Guide for Mapping  Types of Information and Information Systems to Security Categories, August 2008.  http://dx.doi.org/10.6028/NIST.SP.800-60v1r1  767  http://dx.doi.org/10.6028/NIST.IR.7864 http://dx.doi.org/10.6028/NIST.SP.800-30r1 https://www.cnss.gov/CNSS/issuances/Instructions.cfm http://dx.doi.org/10.6028/NIST.SP.800-137 http://csrc.nist.gov/publications/PubsSPs.html#800-117-R1 http://csrc.nist.gov/publications/fips/fips199/FIPS-PUB-199-final.pdf http://dx.doi.org/10.6028/NIST.SP.800-53r4 http://dx.doi.org/10.6028/NIST.SP.800-60v1r1  Executive Summary  1. Introduction  1.1 Purpose and Scope  1.2 Audience  1.3 Document Structure  2. Attack and Defense Basics  2.1 The Attack Side  2.1.1 Vulnerability  2.1.2 Exploit and Attack  2.1.2.1 Intentional  2.1.2.2 Inadvertent  2.1.3 Attack Vector  2.1.4 Threat  2.2 The Defense Side  2.2.1 Risk  2.2.2 Security Controls  2.2.3 Security Objectives  3. Introduction to System and Data-Centric System Threat Modeling  4. Basics of Data-Centric System Threat Modeling  4.1 Step 1: Identify and Characterize the System and Data of Interest  4.2 Step 2: Identify and Select the Attack Vectors to Be Included in the Model  4.3 Step 3: Characterize the Security Controls for Mitigating the Attack Vectors  4.4 Step 4: Analyze the Threat Model  4.5 Customizing the Data-Centric System Threat Modeling Approach  Appendix A— Acronyms and Other Abbreviations  Appendix B— References",
    "original document": "DRAFT Special Publication 800-154, Guide to Data-Centric System Threat Modeling  Draft NIST Special Publication 800-154 1  2  Guide to Data-Centric System  3  Threat Modeling 4  5  6  7  Murugiah Souppaya 8  Karen Scarfone 9  10  11  12  13  14  15  16  C  O  M  P  U  T  E  R  S  E  C  U  R  I  T  Y 17  18  19  Draft NIST Special Publication 800-154 20  21  22  Guide to Data-Centric System  23  Threat Modeling 24  25  26  Murugiah Souppaya 27  Computer Security Division 28  Information Technology Laboratory 29  30  Karen Scarfone 31  Scarfone Cybersecurity 32  Clifton, VA 33  34  35  36  37  38  39  40  March 2016 41  42  43  44  45  46  U.S. Department of Commerce 47  Penny Pritzker, Secretary 48  49  National Institute of Standards and Technology  50  Willie May, Under Secretary of Commerce for Standards and Technology and Director 51  i  Authority 52  This publication has been developed by NIST in accordance with its statutory responsibilities under the 53  Federal Information Security Modernization Act (FISMA) of 2014, 44 U.S.C. § 3541 et seq., Public Law  54  (P.L.) 113-283. NIST is responsible for developing information security standards and guidelines, 55  including minimum requirements for federal information systems, but such standards and guidelines shall 56  not apply to national security systems without the express approval of appropriate federal officials 57  exercising policy authority over such systems. This guideline is consistent with the requirements of the 58  Office of Management and Budget (OMB) Circular A-130. 59  Nothing in this publication should be taken to contradict the standards and guidelines made mandatory 60  and binding on federal agencies by the Secretary of Commerce under statutory authority. Nor should 61  these guidelines be interpreted as altering or superseding the existing authorities of the Secretary of 62  Commerce, Director of the OMB, or any other federal official.  This publication may be used by 63  nongovernmental organizations on a voluntary basis and is not subject to copyright in the United States. 64  Attribution would, however, be appreciated by NIST.  65  National Institute of Standards and Technology Special Publication 800-154 66  Natl. Inst. Stand. Technol. Spec. Publ. 800-154, 25 pages (March 2016) 67  CODEN: NSPUE2 68  Certain commercial entities, equipment, or materials may be identified in this document in order to describe an 69  experimental procedure or concept adequately. Such identification is not intended to imply recommendation or 70  endorsement by NIST, nor is it intended to imply that the entities, materials, or equipment are necessarily the best 71  available for the purpose.  72  There may be references in this publication to other publications currently under development by NIST in 73  accordance with its assigned statutory responsibilities. The information in this publication, including concepts and 74  methodologies, may be used by federal agencies even before the completion of such companion publications. Thus, 75  until each publication is completed, current requirements, guidelines, and procedures, where they exist, remain 76  operative. For planning and transition purposes, federal agencies may wish to closely follow the development of 77  these new publications by NIST.  78  Organizations are encouraged to review all draft publications during public comment periods and provide feedback 79  to NIST. Many NIST cybersecurity publications, other than the ones noted above, are available at 80  http://csrc.nist.gov/publications. 81  82  Public comment period: March 14, 2016 through April 15, 2016 83  All comments are subject to release under the Freedom of Information Act (FOIA). 84  National Institute of Standards and Technology 85  Attn: Computer Security Division, Information Technology Laboratory 86  100 Bureau Drive (Mail Stop 8930) Gaithersburg, MD 20899-8930 87  Email: 800-154comments@nist.gov 88  89  http://csrc.nist.gov/publications  ii  Reports on Computer Systems Technology 90  The Information Technology Laboratory (ITL) at the National Institute of Standards and Technology 91  (NIST) promotes the U.S. economy and public welfare by providing technical leadership for the Nation’s 92  measurement and standards infrastructure. ITL develops tests, test methods, reference data, proof of 93  concept implementations, and technical analyses to advance the development and productive use of 94  information technology. ITL’s responsibilities include the development of management, administrative, 95  technical, and physical standards and guidelines for the cost-effective security and privacy of other than 96  national security-related information in federal information systems. The Special Publication 800-series 97  reports on ITL’s research, guidelines, and outreach efforts in information system security, and its 98  collaborative activities with industry, government, and academic organizations. 99  100  Abstract 101  Threat modeling is a form of risk assessment that models aspects of the attack and defense sides of a 102  particular logical entity, such as a piece of data, an application, a host, a system, or an environment. This 103  publication examines data-centric system threat modeling, which is threat modeling that is focused on 104  protecting particular types of data within systems. The publication provides information on the basics of 105  data-centric system threat modeling so that organizations can successfully use it as part of their risk 106  management processes. The general methodology provided by the publication is not intended to replace 107  existing methodologies, but rather to define fundamental principles that should be part of any sound data-108  centric system threat modeling methodology. 109  110  Keywords 111  data security; information security; risk assessment; risk management; threat modeling; threats; 112  vulnerabilities  113  114  Trademark Information 115  All trademarks or registered trademarks belong to their respective organizations. 116  117  Acknowledgments 118  The authors, Murugiah Souppaya of the National Institute of Standards and Technology (NIST) and 119  Karen Scarfone of Scarfone Cybersecurity, wish to thank their colleagues who reviewed drafts of this 120  document and contributed to its technical content. 121  122  iii  Table of Contents 123  Executive Summary ................................................................................................................. 1 124  1. Introduction ...................................................................................................................... 2 125  1.1 Purpose and Scope ................................................................................................... 2 126  1.2 Audience ................................................................................................................... 2 127  1.3 Document Structure .................................................................................................. 2 128  2. Attack and Defense Basics .............................................................................................. 3 129  2.1 The Attack Side ......................................................................................................... 3 130  2.1.1 Vulnerability .................................................................................................. 3 131  2.1.2 Exploit and Attack ......................................................................................... 4 132  2.1.3 Attack Vector ................................................................................................. 5 133  2.1.4 Threat ........................................................................................................... 6 134  2.2 The Defense Side ...................................................................................................... 7 135  2.2.1 Risk ............................................................................................................... 7 136  2.2.2 Security Controls ........................................................................................... 7 137  2.2.3 Security Objectives ....................................................................................... 7 138  3. Introduction to System and Data-Centric System Threat Modeling ............................. 9 139  4. Basics of Data-Centric System Threat Modeling ..........................................................11 140  4.1 Step 1: Identify and Characterize the System and Data of Interest .......................... 11 141  4.2 Step 2: Identify and Select the Attack Vectors to Be Included in the Model ............. 13 142  4.3 Step 3: Characterize the Security Controls for Mitigating the Attack Vectors ........... 14 143  4.4 Step 4: Analyze the Threat Model ........................................................................... 16 144  4.5 Customizing the Data-Centric System Threat Modeling Approach .......................... 17 145  146  List of Appendices 147  Appendix A— Acronyms and Other Abbreviations ..............................................................19 148  Appendix B— References ......................................................................................................20 149  150  151  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  1  Executive Summary 152  Threat modeling is a form of risk assessment that models aspects of the attack and defense sides of a 153  particular logical entity, such as a piece of data, an application, a host, a system, or an environment. The 154  fundamental principle underlying threat modeling is that there are always limited resources for security 155  and it is necessary to determine how to use those limited resources effectively. There are many types of 156  threat modeling; for example, system threat modeling is threat modeling performed for operational 157  systems to improve their overall security. This publication focuses on one type of system threat modeling: 158  data-centric system threat modeling. Data-centric system threat modeling is threat modeling that is 159  focused on protecting particular types of data within systems. 160  Threat modeling is needed because of the dynamic nature of security. The attack and defense sides of 161  security are constantly changing. As part of handling this change, organizations should continually 162  reassess and evolve their defenses. This includes adopting continuous monitoring practices, security 163  automation technologies, and threat intelligence feeds to detect new vulnerabilities and attacks in near-164  real-time, allowing rapid risk mitigation. Another key component of handling the constant change in 165  security is having security metrics; these can be used for more informed decision making, again often 166  relating to risk management in general and risk mitigation in particular.  167  Increasingly, simply following general “best practices” for security is insufficient for safeguarding high-168  value data. Best practices are largely based on conventional wisdom intended to mitigate common threats 169  and vulnerabilities. By their very nature, such best practices are generalized, especially for ubiquitous 170  products (web browsers, server and desktop operating systems, etc.) They do not take into account the 171  unique characteristics of each system. Also, most best practices are geared toward preventing host 172  compromise and do not take into account the security needs for particular data (again, a more generalized 173  goal versus a specific one). So, for a particular situation, best practices may not include security controls 174  that are necessary to effectively reduce risk.  175  Data-centric system threat modeling allows organizations to consider the security needs of each case of 176  interest, instead of relying solely on generalized “best practice” recommendations. Organizations with 177  strong capabilities in continuous monitoring, security automation, and security metrics should consider 178  adding data-centric system threat modeling based on the principles presented in this publication to 179  supplement these capabilities and achieve demonstrably better security for data of particular importance.  180  181  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  2  1. Introduction 182  1.1 Purpose and Scope 183  Organizations often plan, implement, maintain, and assess the security controls for their systems without 184  performing a methodical analysis of risk involving system threat modeling. The purpose of this 185  publication is to provide information on the basics of system threat modeling so that organizations can 186  successfully use it as part of their risk management processes. 187  There are many forms of threat modeling. This publication’s scope is limited to data-centric system threat 188  modeling, which involves focusing on the security of particular instances of data (such as client 189  information stored on a field agent’s laptop) instead of focusing on the security of particular hosts, 190  operating systems (OS), applications, etc. 191  This publication provides a general methodology that organizations can use. The intent is not to replace 192  existing methodologies, but rather to define fundamental principles that should be part of any sound data-193  centric system threat modeling methodology. 194  1.2 Audience 195  This document is intended for security managers, security engineers/architects, system administrators, and 196  others who are responsible for planning, implementing, and maintaining data and system security 197  controls. Auditors and others who need to assess the security of data and systems may also find this 198  publication useful. 199  1.3 Document Structure 200  The remainder of this document is organized into the following major sections and appendices: 201  • Section 2 discusses attack and defense basics. The terminology and concepts defined in this 202  section are fundamental to understanding the rest of the publication. 203  • Section 3 provides an introduction to general system threat modeling. 204  • Section 4 presents a basic methodology for data-centric system threat modeling, with simplified 205  examples illustrating the use of the methodology. 206  • Appendix A contains an acronym and abbreviation list. 207  • Appendix B lists the references for the document. 208  209  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  3  2. Attack and Defense Basics 210  This section establishes a foundation for the rest of the document by covering the basic concepts of 211  security relevant to threat modeling. It defines fundamental terminology, such as what vulnerabilities and 212  attack vectors are, because of the lack of consensus in the security community as to what such terms 213  mean. It also explains how these concepts work in practice. The discussion is divided into two parts: the 214  attack side (Section 2.1) and the defense side (Section 2.2). This section can be thought of as explaining 215  the problem that threat modeling is trying to solve. The term “threat modeling” is defined in Section 3. 216  2.1 The Attack Side 217  This section defines the basic concepts related to the attack side of threat modeling, grouped by core 218  terms: vulnerability, exploit and attack, attack vector, and threat. Where applicable, it enumerates the 219  major categories of each entity (such as major categories of vulnerabilities). These enumerations are not 220  intended to be comprehensive or authoritative, but instead to help illustrate the potential scope of threat 221  modeling activities. 222  2.1.1 Vulnerability 223  The term “vulnerability” has been defined in many ways over years. This document proposes that a 224  vulnerability is any trust assumption involving people, processes, or technology that can be violated in 225  order to exploit a system. Types of vulnerabilities include the following: 226  • A software flaw vulnerability is caused by an error in the design or coding of software. One 227  example is an input validation error, such as user-provided input being trusted, and thus not being 228  properly evaluated for malicious character strings and overly long values associated with known 229  attacks. Another example is a race condition error that allows the attacker to perform a specific 230  action with elevated privileges. A race condition is possible because the software does not expect 231  certain patterns of activity to occur, in effect trusting that users will not cause such patterns. 232  • A security configuration issue vulnerability involves the use of security configuration settings 233  that negatively affect the security of the software if taken advantage of by users. A security 234  configuration setting is an element of a software’s security that can be altered through the 235  software itself. Examples of settings are an operating system offering access control lists that set 236  user privileges for files, and an application offering a setting to enable or disable the encryption 237  of sensitive data stored by the application. Many configuration settings increase security at the 238  expense of reducing functionality, so using the most secure settings could make the software 239  useless or unusable.  240  • A software feature is a functional capability provided by software. A software feature misuse 241  vulnerability is a vulnerability in which the feature also provides an avenue to compromise the 242  security of a system. These vulnerabilities are caused by the software designer making trust 243  assumptions that permit the software to provide beneficial features, while also introducing the 244  possibility of someone violating the trust assumptions to compromise security. For example, 245  email client software may contain a feature that renders HTML content in email messages. An 246  attacker could craft a fraudulent email message that contains hyperlinks that, when rendered in 247  HTML, appear to the recipient to be benign, but actually take the recipient to a malicious web site 248  when they are clicked on. One of the trust assumptions in the design of the HTML content 249  rendering feature was that users would not receive malicious hyperlinks and click on them. 250  Another example of a software feature misuse vulnerability is an attacker stealing a user’s 251  credentials and reusing them to impersonate the user; the trust assumption was that only the 252  legitimate user would use those credentials. Misuse vulnerabilities are inherent in software 253  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  4  features because each feature is based on trust assumptions—and those assumptions can be 254  broken, albeit involving significant cost and effort in some cases. [1] 255  No system is 100 percent secure: every system has vulnerabilities. At any given time, a system may not 256  have any known software flaws, but security configuration issues and software feature misuse 257  vulnerabilities are always present and cannot even be readily enumerated at this time. A system’s 258  vulnerabilities are likely to have a wide variety of characteristics. Some will be very easy to exploit, while 259  others will only be exploitable under a combination of highly unlikely conditions. One vulnerability 260  might provide root-level access to a system, while another vulnerability might only permit read access to 261  an insignificant file. 262  2.1.2 Exploit and Attack 263  To exploit a vulnerability is to use it to violate security objectives, such as confidentiality, integrity, and 264  availability (see Section 2.2.3 for more information on security objectives). The program code or other 265  commands used to exploit a vulnerability are generically referred to as an exploit or an attack. These 266  meanings, which are specific to the commands, are not to be confused with the verb forms of “exploit” 267  and “attack”, which have different meanings; “to exploit” implies a successful security violation, while 268  “to attack” implies an attempted security violation but not its success or failure. Noun forms of these 269  verbs, referring to the actions, have the same distinction in meanings; an attack (action) that succeeds can 270  also be called an exploit. 271  This document uses the term attacker to refer to a party who attacks a host, network, or other IT resource. 272  However, not all attacks are intentional. Some attacks are performed by users who accidentally or 273  otherwise unintentionally violate security policies, requirements, etc., to the point of compromising 274  security. Because intent often has no relation to the impact of a compromise, this document uses the term 275  “attack” to refer to both intentional and inadvertent compromises. Sections 2.1.2.1 and 2.1.2.2 discuss the 276  individuals who perform attacks in both categories. 277  2.1.2.1 Intentional 278  Attackers who intend to exploit vulnerabilities are motivated by various reasons, ranging from the desire 279  to make political or social statements to financial gain and cyberwarfare. Some attackers are focused on a 280  short-term action, such as a financial transaction, but many attackers, especially those interested in 281  gaining access to sensitive information, may be more interested in long-term infiltration and data 282  gathering. These attacks are often targeted, such as focusing on exploiting a high-value system or 283  individual. 284  The skill sets of attackers vary as widely as their motivations. At one extreme are unskilled individuals 285  who purchase attack toolkits that make basic exploitation almost trivial to perform. At the other extreme 286  are highly skilled individuals who are capable of discovering new vulnerabilities on their own and 287  figuring out how to exploit them. Another important group of attackers to consider is malicious insiders; 288  even though they may not be particularly skilled in exploitation, their level of access and detailed 289  knowledge of the organization’s systems makes them particularly effective at data theft and manipulation. 290  A malicious insider may also work in conjunction with an external attacker, such as insiders selling their 291  usernames and passwords to third parties. 292  Another category of intentional attacks is not directly associated with a particular person or group—for 293  example, malware may have been propagating from system to system for some time and is not being 294  directed or otherwise controlled by anyone. This is not meant to imply that no one is responsible for the 295  malware, but rather that there is not a person specifically launching each instance of the malware. 296  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  5  Because the malware is designed to exploit vulnerabilities, this publication considers all malware-based 297  attacks to be intentional attacks. 298  2.1.2.2 Inadvertent 299  Attackers who inadvertently exploit vulnerabilities are acting either by accident or through a lack of 300  understanding, such as performing actions that they do not know are security violations or do not consider 301  a “real” security problem. 302  2.1.3 Attack Vector 303  An attack vector is a segment of the entire pathway that an attack uses to access a vulnerability. Each 304  attack vector can be thought of as comprising a source of malicious content, a potentially vulnerable 305  processor of that malicious content, and the nature of the malicious content itself. Examples of attack 306  vectors are: 307  • Malicious web page content (content) downloaded from a web site (source) by a vulnerable web 308  browser (processor); 309  • A malicious email attachment (content) in an email client (source) rendered by a vulnerable 310  helper application (processor); 311  • A malicious email attachment (content) downloaded from an email server (source) to a vulnerable 312  email client (processor); 313  • A network service with inherent vulnerabilities (processor) used maliciously (content) by an 314  external endpoint (source); 315  • Social engineering-based conversation (content) performed by phone from a human attacker 316  (source) to get a username and password from a vulnerable user (processor); 317  • Stolen user credentials (content) typed in by an attacker (source) to a web interface for an 318  enterprise authentication system (processor); and 319  • Personal information about a user harvested from social media (content) entered into a password 320  reset website by an attacker (source) to reset a password by taking advantage of weak password 321  reset processes (processor). 322  The characteristics of attacks vary widely. Some involve exploitation of a single vulnerability using a 323  single attack vector, while others involve multiple vulnerabilities and multiple attack vectors, or even a 324  single vulnerability and multiple attack vectors. And the vulnerabilities and attack vectors may be spread 325  across multiple hosts, compromising one host in order to compromise another, further complicating the 326  composition of an attack.  327  Here is an example of a single possible attack involving one vulnerability, decomposed into its attack 328  vectors: 329  1. Malicious email attachment (content) sent from a host (source) to the organization’s primary mail 330  server (processor); 331  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  6  2. Malicious email attachment (content) sent from the organization’s primary mail server (source) to 332  antivirus server (processor); 333  3. Malicious email attachment (content) sent from the antivirus server (source) to the organization’s 334  internal mail server (processor); 335  4. Malicious email attachment (content) sent from the organization’s internal mail server (source) to 336  the user’s email client (processor); and 337  5. Malicious email attachment (content) rendered (processor) by the vulnerable email client 338  (source). 339  Note that although there are five attack vectors, the actual exploitation only occurs during the last of the 340  five (when the malicious attachment is rendered by a vulnerable email client). However, each attack 341  vector affords an opportunity to detect and stop the attack before it goes any farther. 342  Although this example focuses on vulnerabilities in technologies, many attacks include non-technological 343  attack vectors. For example, attackers often use social engineering methods to trick users into revealing 344  their passwords, performing actions that unknowingly grant attackers remote access to systems, and 345  otherwise enabling security to be compromised. Similar attacks may be performed on IT personnel, such 346  as an attacker impersonating a legitimate user and convincing a help desk agent to reset the user’s 347  password to a password selected by the attacker. 348  Because the focus of this publication is modeling threats against a targeted (vulnerable) system, the 349  compromises of greatest interest are those against the ultimate target itself. There are often intermediate 350  hosts used as jumping off points for attacks—in botnets, for example. Analyzing how those intermediate 351  hosts become compromised would fall within the scope of performing an analysis of those individual 352  intermediate hosts themselves as targets, and is outside the scope of analyzing the ultimate target. So, in 353  the previous example with five attack vectors, with the ultimate target being the host with the vulnerable 354  email client, it would be irrelevant to the target how the host in step 1 that originally sent the malicious 355  email attachment was compromised. 356  Other terms are useful when discussing attack vectors. For example, an attack model comprises a scenario 357  that may occur and a single path (one or more attack vectors in sequence) that could be taken for that 358  scenario. The attack models for a scenario and the security controls attempting to disrupt those attack 359  models collectively constitute a threat model.1 Another way to analyze attack vectors is to analyze all of 360  the attack vectors directly against a particular system; this is known as the system’s attack surface. 361  2.1.4 Threat 362  A threat is defined in NIST Special Publication (SP) 800-30 as “any circumstance or event with the 363  potential to adversely impact organizational operations and assets, individuals, other organizations, or the 364  Nation through an information system via unauthorized access, destruction, disclosure, or modification of 365  information, and/or denial of service.” [2, p. B-13] Threats may be intentional or unintentional. A threat 366  source is the cause of a threat, such as a hostile cyber or physical attack, a human error of omission or 367  commission, a failure of organization-controlled hardware or software, or other failure beyond the control 368  of the organization.  369  1  Section 3 contains a more formal definition of the term “threat modeling.”  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  7  A threat event is defined in NIST SP 800-30 as “an event or situation initiated or caused by a threat 370  source that has the potential for causing adverse impact.” [2, p. B-13] The distinction between a threat and 371  a threat event is subtle, but basically a threat event is caused by a particular threat source, while a threat is 372  more generic (not caused by a particular threat source). 373  2.2 The Defense Side 374  This section explains the basic concepts related to the defense side of threat modeling, grouped by core 375  terms: risk, security controls, and security objectives.  376  2.2.1 Risk 377  Committee on National Security Systems Instruction (CNSSI) 4009, National Information Assurance (IA) 378  Glossary, defines risk in general as “a measure of the extent to which an entity is threatened by a potential 379  circumstance or event, and typically a function of: (i) the adverse impacts that would arise if the 380  circumstance or event occurs; and (ii) the likelihood of occurrence” [3, p. 104] and information security 381  risks specifically as “those risks that arise from the loss of confidentiality, integrity, or availability of 382  information or information systems and reflect the potential adverse impacts to organizational operations 383  (including mission, functions, image, or reputation), organizational assets, individuals, other 384  organizations, and the Nation” [3, p. 65]. 385  Risk management is defined in CNSSI 4009  as “the program and supporting processes to manage 386  information security risk to organizational operations….” [3, p. 104]. Part of risk management is risk 387  assessment, which is defined in NIST SP 800-30 as “the process of identifying, prioritizing, and 388  estimating risks to organizational operations (including mission, functions, image, reputation), 389  organizational assets, individuals, other organizations, and the Nation, resulting from the operation of an 390  information system” [2, p. B-9]. Risk assessment considers the possible threats and vulnerabilities, and 391  determines what security controls (see Section 2.2.2) should be used to mitigate them, which means to 392  reduce their risk to an acceptable level. 393  2.2.2 Security Controls 394  CNSSI 4009 defines security controls as “the management, operational, and technical controls (i.e., 395  safeguards or countermeasures) prescribed for an information system to protect the confidentiality, 396  integrity, and availability of the system and its information” [3, p. 110]. Although technical controls can 397  be fully automated, which makes them an obvious choice for stopping attacks, management and 398  operational controls also play important roles. For example, users must be trained on their security 399  responsibilities so that they are less likely to violate security policies, be tricked by phishing attacks, and 400  otherwise decrease the organization’s security posture. Ultimately an organization’s security relies on a 401  combination of people, processes, and technology. 402  2.2.3 Security Objectives 403  Organizations usually think of their security objectives for data in terms of protecting its confidentiality2, 404  integrity, and/or availability.3 In many cases, the security objectives for an instance of data should not all 405  have equal importance, and in some cases, an organization may want to focus its threat modeling efforts 406  2  For the purposes of this publication, privacy objectives will be considered a subset of confidentiality objectives.  3  Some organizations may choose to replace the security objectives with one or more security requirements for threat  modeling purposes. Security requirements are more specific and granular than security objectives, and they often come  directly from the organization’s policies or from regulations or security compliance initiatives that the organization is  subject to.  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  8  on a single objective. For example, if a risk assessment shows that the risk of a breach of confidentiality is 407  unacceptably high, then performing threat modeling for confidentiality only may be most helpful for 408  mitigating the confidentiality breach risk to an acceptable level. Similarly, information that has already 409  been released to the public may still need its integrity and availability protected, but not its 410  confidentiality. 411  Because this publication is addressing data-centric system threat modeling, only security objectives for 412  data—not systems—are pertinent. This means that operational unavailability of systems caused by attacks 413  is out of scope, for example, while operational unavailability of data caused by attacks is in scope.  414  The security objectives relate directly to the risk management, assessment, mitigation, and security 415  control concepts discussed in Sections 2.2.1 and 2.2.2. For example, if the results of risk assessment show 416  that the risk of a breach of confidentiality is unacceptably high, then additional security controls or 417  changes to existing security controls may be needed to mitigate the confidentiality breach risk to an 418  acceptable level. The same is true for integrity and availability. 419  420  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  9  3. Introduction to System and Data-Centric System Threat Modeling 421  This section provides an overview of threat modeling in general, with an emphasis on system and data-422  centric system threat modeling. Threat modeling is a form of risk assessment that models aspects of the 423  attack and defense sides of a particular logical entity, such as a piece of data, an application, a host, a 424  system, or an environment. The fundamental principle underlying threat modeling is that there are always 425  limited resources for security and it is necessary to determine how to use those limited resources 426  effectively. 427  There are many types of threat modeling, and they can be distinguished based on three related 428  characteristics: 429  1. The logical entity being modeled (data, software, system, etc.); 430  2. The phase of the system lifecycle (for example, modeling security for software during its initial 431  design versus modeling security for already-implemented off-the-shelf software, for example); 432  and 433  3. The goal of the threat modeling (to reduce software vulnerabilities, to thwart particular classes of 434  attackers, to improve overall system security, to protect particular types of data, etc.). 435  A common form of threat modeling is software threat modeling, which is threat modeling performed 436  during software design to reduce software vulnerabilities. There are many established methodologies for 437  performing software threat modeling.  438  Another common form of threat modeling is known as system threat modeling, which is threat modeling 439  performed for operational systems to improve their overall security. Compared to software threat 440  modeling, system threat modeling tends to be largely informal and ad hoc.  441  Data-centric system threat modeling is a particular type of system threat modeling, and its basics are 442  described in Section 4. This type of threat modeling is focused on protecting particular types of data 443  within systems. 444  Threat modeling is needed because of the dynamic nature of security. Security would be difficult enough 445  to tackle if it was a one-time endeavor. Unfortunately, the attack side is constantly changing; new 446  vulnerabilities are discovered, new attacks are created, and new threats arise. Long-term changes happen, 447  too—new classes of vulnerabilities are discovered, attacker motivations change, and other 448  transformations occur over years. The defense side of security is also constantly changing—security 449  controls are improved and enhanced, new types of security controls are developed, etc. Change is 450  inevitable; as a particular class of vulnerabilities becomes well mitigated, for example, attackers simply 451  identify another class of vulnerabilities that are not as well mitigated to exploit, and defenders adjust 452  security controls accordingly. 453  As part of handling this constant change, organizations should continually reassess and evolve their 454  defenses. This includes adopting continuous monitoring practices [4], security automation technologies 455  [5], and threat intelligence feeds to detect new vulnerabilities and attack attempts in near-real-time, 456  allowing rapid risk mitigation. Another key component of handling the constant change in security is 457  having security metrics; these can be used for more informed decision making, again often relating to risk 458  management in general and risk mitigation in particular.  459  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  10  Organizations with strong capabilities in continuous monitoring, security automation, and security metrics 460  should consider adding data-centric system threat modeling as described in Section 4 to supplement these 461  capabilities and achieve demonstrably better security for data of particular interest. Quantitative security 462  metrics are more accurate than qualitative ones, but quantitative metrics are presently very difficult for 463  most organizations to collect. Using high-quality qualitative metrics is far better than using no metrics at 464  all. 465  Increasingly, simply following general “best practices” for security is insufficient for safeguarding high-466  value data. Best practices are largely based on conventional wisdom intended to mitigate common threats 467  and vulnerabilities. By their very nature, such best practices are generalized, especially for ubiquitous 468  products (web browsers, server and desktop operating systems, etc.) They do not take into account the 469  unique characteristics of each system. Also, most best practices are geared toward preventing host 470  compromise and do not take into account the security needs for particular data (again, a more generalized 471  goal versus a specific one). So, for a particular situation, best practices may omit security controls that are 472  necessary to effectively reduce risk.  473  Data-centric system threat modeling allows organizations to consider the security needs of each case of 474  interest, instead of relying solely on “best practice” generalized recommendations. Organizations are 475  already very familiar with applying best practices to operating systems and individual applications, such 476  as securing a web server (host) or web server software. What is considerably more challenging for 477  organizations to tackle is determining how to secure a particular chunk of data. It is not that securing a 478  piece of data is so difficult, but that traditionally security professionals, system administrators, and others 479  responsible for securing operational systems have focused on securing systems, not data. The rest of this 480  publication focuses on data security. 481  This differentiation between system and data security has parallels to existing NIST publications. A 482  system security approach starts with a FIPS 199 [6] low/moderate/high impact rating for a system, and 483  then selects the corresponding security controls from NIST SP 800-53 [7]. In contrast, a data security 484  approach starts with a publication such as NIST SP 800-60 [8] for categorizing the type of information. 485  486  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  11  4. Basics of Data-Centric System Threat Modeling 487  Data-centric system threat modeling brings together the attack and defense side information for data of 488  interest in a standardized model that facilitates security analysis, decision making, and change planning. 489  This section provides information on the fundamentals of data-centric system threat modeling. This 490  publication is not trying to define a new threat modeling methodology, but rather to educate organizations 491  on the fundamentals of data-centric system threat modeling and to make recommendations related to the 492  use of this type of modeling. 493  The data-centric system threat modeling approach presented in this publication has four major steps: 494  1. Identify and characterize the system and data of interest; 495  2. Identify and select the attack vectors to be included in the model; 496  3. Characterize the security controls for mitigating the attack vectors; and 497  4. Analyze the threat model. 498  Sections 4.1 through 4.4 provide more information on performing each of these steps. Each step is also 499  illustrated by examples, which are denoted by a border around the text. The same example is continued 500  throughout all of the steps. Note that the data presented in the example is hypothetical and meant solely 501  for providing a simplified illustration of the steps. 502  Section 4.5 explains in detail that this approach to data-centric system threat modeling is intended to be 503  customized to meet the needs of each organization, and it shows how easily this customization can occur.  504  4.1 Step 1: Identify and Characterize the System and Data of Interest 505  The first step is to identify and characterize the system and data of interest. The system and data should be 506  defined narrowly, pertaining to a particular logical set of data on a particular host or small group of 507  closely related hosts and devices.  508  Once the system and data are defined, they need to be characterized, which refers to understanding the 509  system’s operation and usage to the extent needed for the organization’s data-centric system threat 510  modeling approach. At an absolute minimum, characterization should include the following: 511  • The authorized locations for the data within the system.4 This will include some or all of the 512  following: 513  o Storage: all places where data may be at rest within the system boundaries; 514  o Transmission: all ways in which data may transit over networks between system components 515  and across the system’s boundaries; 516  o Execution environment: e.g., data held in local memory during runtime, data processed by 517  virtual CPUs, etc.; 518  o Input: e.g., data typed in using the keyboard; and 519  4  The methodology identifies just the authorized locations because someone with access to the data could store, transmit,  output, or otherwise place the data in any accessible location, authorized or not, including locations outside the system  boundaries.  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  12  o Output: e.g., data printed to a physically attached printer, data displayed on the laptop screen, 520  etc. 521  • A basic understanding of how the data moves within the system between authorized 522  locations. For example, a file might be held in memory while it is being created and is only 523  written out to storage when the user directs the system to do so. Depending on the complexity of 524  the system, gaining this understanding may require first understanding the system’s functions and 525  processes, users and usage scenarios, workflows, trust assumptions, and other aspects of people, 526  processes, and technology related to the system. 527  • The security objectives (e.g., confidentiality, integrity, availability) for the data. In many 528  cases, some objectives are more important than others; in other cases, an organization may want 529  to focus on a single objective for a particular threat model.5 530  • The people and processes who are authorized to access the data in a way that could affect 531  the security objectives. For example, if an organization has selected confidentiality as its sole 532  objective for a particular threat model, the authorized people and processes should include all 533  users, administrators, applications, services, etc. who are allowed to read the data. 534  Example Scenario 535  Summary: The data of interest is a spreadsheet containing personally identifiable information (PII) for 536  employees who have received workers’ compensation.  537  The system of interest comprises: 538  • a human resource specialist’s laptop (spreadsheet is stored on and used from the laptop); 539  • a USB flash drive (spreadsheet is backed up onto the USB flash drive); and 540  • a printer (spreadsheet can be printed from the laptop to the printer). 541  The authorized locations for the data of interest are as follows: 542  • Storage: Spreadsheet kept on a laptop hard drive, backup of spreadsheet kept on a USB flash drive; 543  • Transmission: Sent to a printer over a wireless network; 544  • Execution environment: Local laptop memory and processors; 545  • Input: Typed in using the laptop keyboard; and 546  • Output: Displayed to the screen. 547  548  Description: Data is input through the keyboard into the spreadsheet, which is temporarily held in the 549  execution environment. As the user updates the spreadsheet, the data is displayed to the screen. When the 550  user has completed editing the spreadsheet, the user directs the system to save the spreadsheet to the 551  laptop hard drive. The user may also load the spreadsheet into the execution environment and print the 552  spreadsheet to a nearby printer through a wireless network connection. Finally, the user occasionally 553  copies the latest version of the spreadsheet from the laptop hard drive to a USB flash drive as a backup. 554  5  Some organizations may choose to replace the security objectives with one or more security requirements. Security  requirements are more specific and granular than security objectives, and they often come directly from the organization’s  policies or from regulations or security compliance initiatives that the organization is subject to.  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  13  Although confidentiality, integrity, and availability all matter for the data of interest, confidentiality is 555  considered so much more important that the organization has decided to perform its trust modeling in 556  terms of confidentiality only. 557  In this highly simplified example, the human resource specialist is the only person who is authorized to 558  access the data. 559  4.2 Step 2: Identify and Select the Attack Vectors to Be Included in the Model 560  The second step involves identifying the potential attack vectors, as discussed in Section 2.1.3, that could 561  be used to negatively impact one or more of the identified security objectives for one of the authorized 562  locations for the data. Once the attack vectors are identified, it may be necessary to select only a subset of 563  those attack vectors to be included in the threat model. Although it is generally preferable to include all 564  the attack vectors, there are often too many to be addressed with limited resources. Possible criteria to 565  consider include the relative likelihood of the attack vector being used and the most likely impact of a 566  successful attack. See Section 4.5 below for more information on the selection process. 567  Location 1: Stored in a spreadsheet on the local hard drive. 568  • Vector 1a: Attacker gains unauthorized physical access to the laptop, uses forensic tools or other 569  utilities to copy the file (without authenticating to the OS). 570  • Vector 1b: Attacker gains unauthorized physical access to the laptop, exploits vulnerabilities to gain 571  OS access (impersonating user/admin). 572  • Vector 1c: Attacker steals and reuses user/admin/service credentials. 573  • Vector 1d: Attacker gains access to/control over user’s session/device. 574  • Vector 1e: User forwards the file to an unauthorized recipient (user was tricked via social 575  engineering, user is malicious, user made a mistake, etc.). 576  • Vector 1f: Attacker accesses unsecured network service (e.g., connects to unsecured file share) and 577  gains access to the file. 578  579  Location 2: Stored in a spreadsheet on a flash drive backup. 580  • Vector 2a: Attacker gains unauthorized physical access to the flash drive, mounts the drive and 581  copies the file. 582  • Vector 2b: Attacker steals and reuses user/admin/service credentials for laptop while flash drive is 583  mounted.  584  • Vector 2c: Attacker gains access to/control over user’s session/device while flash drive is mounted.  585  • Vector 2d: User forwards the file to an unauthorized recipient.  586  587  Location 3: Printed to a nearby printer over a wireless network connection. 588  • Vector 3a: Attacker monitors unencrypted or weakly encrypted wireless network communications 589  and captures the data being sent to the printer. 590  • Vector 3b: Attacker views a printout of the spreadsheet. 591  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  14  592  Location 4: Processed locally. 593  • Vector 4a: Attacker gains access to/control over user’s session/device. 594  595  Location 5: Input locally. 596  • Vector 5a: Attacker watches the information being typed in to the laptop. 597  • Vector 5b: Attacker uses keystroke logger on laptop to monitor keystrokes. 598  599  Location 6: Output locally. 600  • Vector 6a: Attacker views the information on the laptop screen. 601  • Vector 6b: Attacker uses malware on laptop to take screen shots. 602  603  Selected attack vectors (based on the possibility and the likelihood of each attack vector being used to 604  completely compromise confidentiality): 605  o Vector 1c: Data is stored in a spreadsheet on the local hard drive; attacker steals and reuses 606  user/admin/service credentials. 607  o Vector 1d: Data is stored in a spreadsheet on the local hard drive; attacker gains access to/control 608  over user’s session/device. 609  o Vector 2b: Data is stored in a spreadsheet on a flash drive backup; attacker steals and reuses 610  user/admin/service credentials for laptop while flash drive is mounted. 611  o Vector 2c: Data is stored in a spreadsheet on a flash drive backup; attacker gains access to/control 612  over user’s session/device while flash drive is mounted. 613  o Vector 4a: Data is processed locally; attacker gains access to/control over user’s session/device. 614  615  4.3 Step 3: Characterize the Security Controls for Mitigating the Attack Vectors 616  The third step of the methodology is, for each attack vector selected in Step 2, to identify and document 617  security control alterations (additions to existing security controls, reconfigurations of existing security 618  controls, etc.) that would help mitigate the risk associated with the attack vector and that are reasonably 619  feasible to accomplish. Note that it is not necessarily to enumerate every single applicable control, such as 620  having a security program and policies, because these controls should already be in place for the entire 621  enterprise and are not normally customized to take a particular attack vector into consideration. 622  Next, for each selected security control alteration, estimate how effectively it would address exploitation 623  of each applicable attack vector. This could be as simple as ranking effectiveness as low, medium, or 624  high, or as complex as estimating the percentage of attacks against the attack vector that would be stopped 625  by this mitigation. Whatever method is selected, it should be comparable across mitigations and attack 626  vectors. 627  The counterpart to estimating the effectiveness of each security control alteration is estimating the 628  negative implications. Factors to consider may include cost (perhaps the order of magnitude or the range 629  of costs for acquisition and implementation, and for annual management/maintenance) and reductions in 630  functionality, usability, and performance. These can be particularly hard to determine accurately for 631  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  15  future mitigations, so it may be necessary to develop very rough estimates for them using a simple 632  low/medium/high type scale that is particular to the organization. 633  Feasible security control alterations: 634  1. Require strong password with strongly encrypted password hash (vectors 1c and 2b). 635  • Effectiveness: Low  636  • Acquisition and implementation costs: Low 637  • Annual management/maintenance costs: Low 638  • Impact on functionality: Low 639  • Impact on usability: Low 640  • Impact on performance: Low 641  642  2. Require multifactor authentication (vectors 1c and 2b) 643  • Effectiveness: High  644  • Acquisition and implementation costs: Moderate 645  • Annual management/maintenance costs: Moderate 646  • Impact on functionality: Low 647  • Impact on usability: Moderate 648  • Impact on performance: Low 649  650  3. Use antivirus software, spam filtering, real-time blacklists, user awareness, web reputation software, 651  etc. (vectors 1c, 1d, 2b, 2c, and 4a) 652  • Effectiveness: Moderate 653  • Acquisition and implementation costs: Moderate 654  • Annual management/maintenance costs: Moderate 655  • Impact on functionality: Moderate 656  • Impact on usability: Moderate 657  • Impact on performance: Moderate 658  659  4. Patch vulnerabilities (vectors 1c, 1d, 2b, 2c, and 4a) 660  • Effectiveness: Low 661  • Acquisition and implementation costs: Moderate 662  • Annual management/maintenance costs: Moderate 663  • Impact on functionality: Moderate 664  • Impact on usability: Low 665  • Impact on performance: Moderate 666  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  16  667  4.4 Step 4: Analyze the Threat Model 668  The final step of the methodology is to analyze all the characteristics documented during the previous 669  steps, which collectively comprise the threat model, to assist in evaluating the effectiveness and efficiency 670  of each security control option against the selected attack vectors. It is far too simplistic to say that a 671  control should be applied because it lowers risk. In addition to their financial costs in terms of acquisition, 672  implementation, and management/maintenance, security controls can negatively impact functionality, 673  usability, and performance, among other factors. Any assessment of security controls should include 674  considerations of all significant relevant factors. 675  The most challenging part of threat model analysis is determining how to consider all of these 676  characteristics together. It is straightforward to compare an individual characteristic, such as the annual 677  management/maintenance costs, across attack vectors and mitigations. However, it is not straightforward 678  at all to compare the entire set of characteristics for an attack vector against the entire set of 679  characteristics for another attack vector. Yet such comparisons are absolutely critical to determining how 680  risk can best be reduced across all the attack vectors, in a cost-effective manner that has an acceptable 681  negative impact on the organization’s operations. Each organization needs to determine how to compare 682  the characteristics for each attack vector/security control pair, as a basis for comparing attack vector 683  characteristics and security control characteristics. 684  One approach to facilitating these comparisons is to assign scores and weightings to each characteristic. 685  For example, the narrative descriptions of threat consequence could be converted to numerical values on a 686  three-point scale. Three-point scales could also be used for other characteristics in place of low, medium, 687  and high ratings. Even complex characteristics, such as cost, could be mapped to a simple scale. 688  In addition to assigning scores to each characteristic’s possible values or value ranges, the organization 689  also needs to consider the relative weights of each characteristic. Perhaps the effectiveness against attacks 690  is considered much more important than other characteristics; if so, this could be conveyed by doubling or 691  tripling its score. Similarly, all other characteristics could be assigned a multiplier that would increase or 692  decrease their scores or keep them the same. Then after applying the multipliers, the organization would 693  add up the results and have a relative score for each attack vector/security control pair.  694  Another scoring approach that could be followed in addition to the previously described approach is to set 695  thresholds or rules for certain criteria and eliminate from further consideration any attack vector/security 696  control pairs that do not meet these. A simple example is eliminating all pairs that have a cost of $100,000 697  or more over a period of three years. A more complex example is eliminating all pairs that have a cost of 698  $50,000 or more over a period of three years AND a high impact on usability AND low or medium 699  effectiveness against attacks. 700  After much debate, the organization decides to set the following scores for the characteristics and weigh 701  them all evenly: 702  • No security control effectiveness = 0 703  • Security control effectiveness of low = 1 704  • Security control effectiveness of moderate = 2 705  • Security control effectiveness of high = 3 706  • Negative implication of high = 1 707  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  17  • Negative implication of moderate = 2 708  • Negative implication of low = 3 709  The organization calculates the total of the negative implication scores for each security control (see first 710  table below), then multiplies these totals by the score of the security control effectiveness per attack 711  vector (see second table below) to reach a score for each attack vector/security control pair (see shaded 712  area of the second table below). The higher the score, the more “bang for the buck” the security control 713  will provide against the corresponding attack vector. This information is now ready for use in decision 714  making. 715  716  Possible Security Controls  A cq  ui si  tio n  an d  Im pl  em en  ta tio  n  C  os ts  A nn  ua l M  an ag  em en  t/  M  ai nt  en an  ce  C  os ts  Im pa  ct  o  n  Fu  nc tio  na lit  y  Im pa  ct  o  n  U  sa bi  lit y  Im pa  ct  o  n  Pe  rf or  m an  ce  To ta  l f or  S ec  ur ity  C  on tr  ol  Require strong password with strongly encrypted password  hash 3 3 3 3 3 15  Require multifactor authentication 2 2 3 2 3 12  Use antivirus software, spam filtering, real-time blacklists, user  awareness, web reputation software, etc. 2 2 2 2 2 10  Patch vulnerabilities 2 2 2 3 2 11  717  Possible Security Controls  Security Control  Effectiveness Per  Attack Vector  Negative  Implication  Total  Security Control Effectiveness  Times Negative Implication Total  Per Attack Vector  1c 1d 2b 2c 4a 1c 1d 2b 2c 4a  Require strong password with  strongly encrypted password  hash  1 0 1 0 0 15 15 0 15 0 0  Require multifactor  authentication 3 0 3 0 0 12 36 0 36 0 0  Use antivirus software, spam  filtering, real-time blacklists,  user awareness, web  reputation software, etc.  2 2 2 2 2 10 20 20 20 20 20  Patch vulnerabilities 1 1 1 1 1 11 11 11 11 11 11  718  4.5 Customizing the Data-Centric System Threat Modeling Approach 719  This publication presents a primarily qualitative approach to data-centric system threat modeling. A 720  quantitative approach would lead to more precise and accurate results than a qualitative approach, but 721  quantitative approaches would also be much more resource-intensive and would not scale well for 722  modeling large and complex systems unless the metrics and methodologies are mostly automated. 723  Because such automation is not yet widely available, if at all, this publication focuses on qualitative 724  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  18  modeling, which is still quite beneficial. In the future, as more automated quantitative metrics and 725  methodologies become available, organizations should reconsider the feasibility of using quantitative 726  modeling. 727  Most of the actions within the methodology can be addressed in a wide variety of ways in terms of both 728  content (what information is captured) and format/structure (how that information is captured). There is 729  no “right” method, and the examples are purely illustrative. What is important is recording sufficient 730  information to provide the necessary input for subsequent steps and a basis for making actionable 731  recommendations. 732  A prime example of the flexibility of the methodology is Step 2. Step 2 uses the list from Step 1 of 733  authorized locations for the data of interest. In the example, each attack vector is defined in a narrative 734  way, such as “Attacker gains unauthorized physical access to the laptop, uses forensic tools or other 735  utilities to copy the file (without authenticating to the OS).” This single statement actually conveys three 736  pieces of data: 1) a source of malicious content, 2) a potentially vulnerable processor of that malicious 737  content, and 3) the nature of the malicious content itself.  738  Some organizations may prefer a more narrative approach to defining attack vectors because it is easier 739  for others to understand, while other organizations may want a more thorough or technically-based 740  approach and therefore want to go through the threat consequences and actions as a taxonomy for 741  identifying the attack vectors. And, of course, there are many other ways of defining attack vectors that 742  individual organizations may prefer to use because of existing processes and tools or for other reasons. 743  Another factor to consider is the granularity of the attack vectors; one organization may only have the 744  resources to consider the attack vectors at a truly high level, while another organization may want to do a 745  deep dive and make the attack vectors as narrow as possible. 746  Organizations may also want to scope their threat modeling so it takes less effort. Using Step 2 as an 747  example, an organization may decide to eliminate any attack vectors that do not merit further 748  consideration. For example, an organization may decide that attack vectors with the lowest relative 749  likelihood should be ignored because there are far too many other attack vectors to be considered. 750  Similarly, an organization may only be interested (at least initially) in attack vectors that are likely to lead 751  to a complete compromise of confidentiality, integrity, and availability. Another possibility is to eliminate 752  attack vectors that do not have any feasible mitigations. Ideally an organization should analyze all attack 753  vectors before winnowing out any—for example, an unlikely attack vector may turn out to be incredibly 754  easy and inexpensive to mitigate, or a single mitigation may address multiple attack vectors—but 755  realistically this may not be feasible in some cases. 756  Of course, an organization can skip any of the elements of the methodology that are not relevant for a 757  particular situation or environment, and likewise an organization can add characteristics if other factors 758  are also important to the organization. 759  760  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  19  Appendix A—Acronyms and Other Abbreviations 761  Selected acronyms and other abbreviations used in the guide are defined below. 762  CMSS Common Misuse Scoring System  CNSSI Committee on National Security Systems Instruction  FIPS Federal Information Processing Standard  FISMA  Federal Information Security Modernization Act  FOIA Freedom of Information Act  HTML Hypertext Markup Language  IA Information Assurance  IR Interagency Report  IT  Information Technology  ITL Information Technology Laboratory  NIST  National Institute of Standards and Technology  OMB  Office of Management and Budget  OS Operating System  PII Personally Identifiable Information  RFC Request for Comments  SCAP Security Content Automation Protocol  SP  Special Publication  USB Universal Serial Bus  763  764  NIST SP 800-154 (DRAFT)  GUIDE TO DATA-CENTRIC SYSTEM THREAT MODELING  20  Appendix B—References 765  This appendix lists the references for the document. 766  [1] E. LeMay, K. Scarfone, and P. Mell, National Institute of Standards and Technology (NIST)  Interagency Report (IR) 7864, The Common Misuse Scoring System (CMSS): Metrics for  Software Feature Misuse Vulnerabilities, July 2012. http://dx.doi.org/10.6028/NIST.IR.7864  [2] Joint Task Force Transformation Initiative, National Institute of Standards and Technology  (NIST) Special Publication (SP) 800-30 Revision 1, Guide for Conducting Risk Assessments,  September 2012. http://dx.doi.org/10.6028/NIST.SP.800-30r1  [3] Committee on National Security Systems (CNSS), CNSS Instruction No. 4009, National  Information Assurance (IA) Glossary, April 6, 2015.  https://www.cnss.gov/CNSS/issuances/Instructions.cfm  [4] K. Dempsey, N. Chawla, A. Johnson, R. Johnston, A. Jones, A. Orebaugh, M. Scholl, and K.  Stine, National Institute of Standards and Technology (NIST) Special Publication (SP) 800- 137, Information Security Continuous Monitoring (ISCM) for Federal Information Systems and  Organizations, September 2011. http://dx.doi.org/10.6028/NIST.SP.800-137  [5] S. Quinn, K. Scarfone, and D. Waltermire, National Institute of Standards and Technology  (NIST) Special Publication (SP) 800-117 Revision 1 (Draft), Guide to Adopting and Using the  Security Content Automation Protocol (SCAP) Version 1.2, January 2012.  http://csrc.nist.gov/publications/PubsSPs.html#800-117-R1  [6] National Institute of Standards and Technology (NIST) Federal Information Processing  Standard (FIPS) Publication (PUB) 199, Standards for Security Categorization of Federal  Information and Information Systems, February 2004.  http://csrc.nist.gov/publications/fips/fips199/FIPS-PUB-199-final.pdf  [7] Joint Task Force Transformation Initiative, National Institute of Standards and Technology  (NIST) Special Publication (SP) 800-53 Revision 4, Security and Privacy Controls for Federal  Information Systems and Organizations, April 2013 (including updates as of January 22, 2015).  http://dx.doi.org/10.6028/NIST.SP.800-53r4  [8] K. Stine, R. Kissel, W. Barker, J. Fahlsing, and J. Gulick, National Institute of Standards and  Technology (NIST) Special Publication (SP) 800-60 Revision 1, Volume 1: Guide for Mapping  Types of Information and Information Systems to Security Categories, August 2008.  http://dx.doi.org/10.6028/NIST.SP.800-60v1r1  767  http://dx.doi.org/10.6028/NIST.IR.7864 http://dx.doi.org/10.6028/NIST.SP.800-30r1 https://www.cnss.gov/CNSS/issuances/Instructions.cfm http://dx.doi.org/10.6028/NIST.SP.800-137 http://csrc.nist.gov/publications/PubsSPs.html#800-117-R1 http://csrc.nist.gov/publications/fips/fips199/FIPS-PUB-199-final.pdf http://dx.doi.org/10.6028/NIST.SP.800-53r4 http://dx.doi.org/10.6028/NIST.SP.800-60v1r1  Executive Summary  1. Introduction  1.1 Purpose and Scope  1.2 Audience  1.3 Document Structure  2. Attack and Defense Basics  2.1 The Attack Side  2.1.1 Vulnerability  2.1.2 Exploit and Attack  2.1.2.1 Intentional  2.1.2.2 Inadvertent  2.1.3 Attack Vector  2.1.4 Threat  2.2 The Defense Side  2.2.1 Risk  2.2.2 Security Controls  2.2.3 Security Objectives  3. Introduction to System and Data-Centric System Threat Modeling  4. Basics of Data-Centric System Threat Modeling  4.1 Step 1: Identify and Characterize the System and Data of Interest  4.2 Step 2: Identify and Select the Attack Vectors to Be Included in the Model  4.3 Step 3: Characterize the Security Controls for Mitigating the Attack Vectors  4.4 Step 4: Analyze the Threat Model  4.5 Customizing the Data-Centric System Threat Modeling Approach  Appendix A— Acronyms and Other Abbreviations  Appendix B— References",
    "abstract": ""
}
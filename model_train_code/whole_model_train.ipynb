{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datamodule import Sec_Data_Module\n",
    "from model import Sec_Classifier\n",
    "from config import config\n",
    "import os\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = ['xlm-roberta-base', 'bert-base-uncased', 'jackaduma/SecRoBERTa']\n",
    "for model_name in model_list:\n",
    "    config['model_name'] = model_name\n",
    "    epoch_num = config['n_epochs']\n",
    "\n",
    "    print(f\"{epoch_num}epoch train started!\")\n",
    "\n",
    "    model_name = config['model_name'].split('/')[-1]\n",
    "    data_path = f'../{model_name}_dataset/'\n",
    "    train_path = data_path + 'train.pkl'\n",
    "    val_path = data_path + 'val.pkl'\n",
    "\n",
    "    data_module = Sec_Data_Module(train_path, val_path, batch_size=config['batch_size'], model_name=config['model_name'], max_token_len=512)\n",
    "    data_module.setup()\n",
    "    config['train_size'] = len(data_module.train_dataloader())\n",
    "    model = Sec_Classifier(config)\n",
    "\n",
    "    trainer = pl.Trainer(max_epochs=config['n_epochs'], num_sanity_val_steps=-1, accelerator=\"gpu\", devices=1)\n",
    "    # trainer = pl.Trainer(max_epochs=config['n_epochs'], num_sanity_val_steps=-1, accelerator=\"gpu\", devices=-1, strategy=\"ddp_find_unused_parameters_true\")\n",
    "    # trainer = pl.Trainer(max_epochs=config['n_epochs'], accelerator=\"gpu\", devices=4, strategy=\"dp\")\n",
    "    trainer.fit(model, data_module)\n",
    "\n",
    "    if not os.path.exists(f'{model_name}_ckpt'):\n",
    "        os.mkdir(f'{model_name}_ckpt')\n",
    "\n",
    "    model_save_dir = f'./{model_name}_ckpt/'\n",
    "\n",
    "    # trainer.save_checkpoint(model_save_dir, f'{model_name}_{epoch_num}Model.ckpt')\n",
    "\n",
    "    # predictions = trainer.predict(model, data_module)\n",
    "    # torch.save(model.state_dict(), model_save_dir+f'{model_name}_{epoch_num}Model.pth')\n",
    "\n",
    "    # with open(pred_path+f'{sample_num}SamplePredictions.pickle', 'wb') as fw:\n",
    "    #     pickle.dump(predictions, fw)\n",
    "\n",
    "    print(f\"{epoch_num}epoch train completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patent_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 저장된 prediction test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "\n",
    "train_df = pd.read_pickle(os.path.join(f'{model_name}_dataset', 'train.pkl'))\n",
    "val_df = pd.read_pickle(os.path.join(f'{model_name}_dataset', 'val.pkl'))\n",
    "# test_df = pd.read_pickle(os.path.join(f'{model_name}_dataset', 'test.pkl'))\n",
    "\n",
    "train_true_label = train_df['label']\n",
    "val_true_label = val_df['label']\n",
    "# test_true_label = test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_acc(df, predict, label):\n",
    "    index = df.loc[df['label']==label].index\n",
    "    return (predict[index] == label).sum() / len(index)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def document_acc(df, predict):\n",
    "    is_correct = []\n",
    "    docs_index = df['docs_index'].drop_duplicates()\n",
    "    for i in docs_index:\n",
    "        index = df.loc[df['docs_index']==i].index\n",
    "        docs_label = df.loc[df['docs_index']==i]['label'].iloc[0]\n",
    "        predicted_label = Counter(predict[index]).most_common(1)[0][0]\n",
    "        is_correct.append(predicted_label==docs_label)\n",
    "    \n",
    "    return np.array(is_correct).sum() / len(is_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f1 = []\n",
    "train_acc = {\n",
    "    'label0': [],\n",
    "    'label1': [],\n",
    "    'label2': [],\n",
    "    'whole': [],\n",
    "    'docs': []\n",
    "}\n",
    "val_f1 = []\n",
    "val_acc = {\n",
    "    'label0': [],\n",
    "    'label1': [],\n",
    "    'label2': [],\n",
    "    'whole': [],\n",
    "    'docs': []\n",
    "}\n",
    "\n",
    "for i in range(20):\n",
    "    valid_predict = torch.load(os.path.join(f'{model_name}_val_predictions', f'{i}valid.pkl'), map_location=torch.device('cpu'))\n",
    "    val_flatten_predictions = np.stack([torch.softmax(torch.Tensor(p), dim=0).cpu().detach().numpy() for batch in valid_predict for p in batch])\n",
    "\n",
    "    valid_predicts_label = np.argmax(val_flatten_predictions, axis=1)\n",
    "\n",
    "    val_f1.append(f1_score(val_true_label, valid_predicts_label, average='macro'))\n",
    "    val_acc['whole'].append(accuracy_score(val_true_label, valid_predicts_label))\n",
    "\n",
    "    val_acc['docs'].append(document_acc(val_df, valid_predicts_label))\n",
    "\n",
    "    print(f\"{i}번째 점수\")\n",
    "    print(f\"{i}train f1: {train_f1[i]}\")\n",
    "    print(f\"{i}val f1: {val_f1[i]}\")\n",
    "    print(f\"{i}train acc: {train_acc['whole'][i]}\")\n",
    "    print(f\"{i}val acc: {val_acc['whole'][i]}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
